{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build your own NER Tagger\n",
    "\n",
    "__Named Entity Recognition (NER)__ , also known as entity chunking/extraction , is a popular technique used in information extraction to identify and segment the named entities and classify or categorize them under various predefined classes.\n",
    "\n",
    "There are various off the shelf solutions which offer capabilites to perform named entity extraction (some of which we discussed in the previous units). Yet there are times when the requirements are beyond the capabilities of off-the-shelf classifiers.\n",
    "\n",
    "In this notebook, we will go through an exercise to build our own NER using Conditional Random Fields.\n",
    "We would be utilizing ```sklearn_crfsuite``` to develop our NER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "Named Entity Recognition is a sequence modeling problem at it's core. It is more related to classification class of problems where in we need a labeled dataset to train a classifier. \n",
    "\n",
    "There are various labeled datasets for NER class of problems. We would be utilizing a pre-processed version of __GMB (Groningen Meaning Bank) corpus__ for this notebook. The preprocessed version is availble at the following link : [kaggle/ner](https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus)\n",
    "\n",
    "We have provided the dataset in the code repository itself using some intelligent compression and you can access it directly from `pandas` as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count    Dtype \n",
      "---  ------      --------------    ----- \n",
      " 0   Sentence #  47959 non-null    object\n",
      " 1   Word        1048575 non-null  object\n",
      " 2   POS         1048575 non-null  object\n",
      " 3   Tag         1048575 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 32.0+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('ner_dataset.csv.gz', compression='gzip', encoding='ISO-8859-1')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1048565</th>\n",
       "      <th>1048566</th>\n",
       "      <th>1048567</th>\n",
       "      <th>1048568</th>\n",
       "      <th>1048569</th>\n",
       "      <th>1048570</th>\n",
       "      <th>1048571</th>\n",
       "      <th>1048572</th>\n",
       "      <th>1048573</th>\n",
       "      <th>1048574</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sentence #</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>have</td>\n",
       "      <td>marched</td>\n",
       "      <td>through</td>\n",
       "      <td>London</td>\n",
       "      <td>to</td>\n",
       "      <td>protest</td>\n",
       "      <td>the</td>\n",
       "      <td>...</td>\n",
       "      <td>impact</td>\n",
       "      <td>.</td>\n",
       "      <td>Indian</td>\n",
       "      <td>forces</td>\n",
       "      <td>said</td>\n",
       "      <td>they</td>\n",
       "      <td>responded</td>\n",
       "      <td>to</td>\n",
       "      <td>the</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS</th>\n",
       "      <td>NNS</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VBN</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>TO</td>\n",
       "      <td>VB</td>\n",
       "      <td>DT</td>\n",
       "      <td>...</td>\n",
       "      <td>NN</td>\n",
       "      <td>.</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NNS</td>\n",
       "      <td>VBD</td>\n",
       "      <td>PRP</td>\n",
       "      <td>VBD</td>\n",
       "      <td>TO</td>\n",
       "      <td>DT</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tag</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-geo</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-gpe</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 1048575 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0       1              2       3        4        5        \\\n",
       "Sentence #  Sentence: 1     NaN            NaN     NaN      NaN      NaN   \n",
       "Word          Thousands      of  demonstrators    have  marched  through   \n",
       "POS                 NNS      IN            NNS     VBP      VBN       IN   \n",
       "Tag                   O       O              O       O        O        O   \n",
       "\n",
       "           6       7        8       9        ... 1048565 1048566  \\\n",
       "Sentence #     NaN     NaN      NaN     NaN  ...     NaN     NaN   \n",
       "Word        London      to  protest     the  ...  impact       .   \n",
       "POS            NNP      TO       VB      DT  ...      NN       .   \n",
       "Tag          B-geo       O        O       O  ...       O       O   \n",
       "\n",
       "                    1048567 1048568 1048569 1048570    1048571 1048572  \\\n",
       "Sentence #  Sentence: 47959     NaN     NaN     NaN        NaN     NaN   \n",
       "Word                 Indian  forces    said    they  responded      to   \n",
       "POS                      JJ     NNS     VBD     PRP        VBD      TO   \n",
       "Tag                   B-gpe       O       O       O          O       O   \n",
       "\n",
       "           1048573 1048574  \n",
       "Sentence #     NaN     NaN  \n",
       "Word           the  attack  \n",
       "POS             DT      NN  \n",
       "Tag              O       O  \n",
       "\n",
       "[4 rows x 1048575 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count    Dtype \n",
      "---  ------      --------------    ----- \n",
      " 0   Sentence #  1048575 non-null  object\n",
      " 1   Word        1048575 non-null  object\n",
      " 2   POS         1048575 non-null  object\n",
      " 3   Tag         1048575 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 32.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.fillna(method='ffill')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1048565</th>\n",
       "      <th>1048566</th>\n",
       "      <th>1048567</th>\n",
       "      <th>1048568</th>\n",
       "      <th>1048569</th>\n",
       "      <th>1048570</th>\n",
       "      <th>1048571</th>\n",
       "      <th>1048572</th>\n",
       "      <th>1048573</th>\n",
       "      <th>1048574</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sentence #</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>...</td>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>have</td>\n",
       "      <td>marched</td>\n",
       "      <td>through</td>\n",
       "      <td>London</td>\n",
       "      <td>to</td>\n",
       "      <td>protest</td>\n",
       "      <td>the</td>\n",
       "      <td>...</td>\n",
       "      <td>impact</td>\n",
       "      <td>.</td>\n",
       "      <td>Indian</td>\n",
       "      <td>forces</td>\n",
       "      <td>said</td>\n",
       "      <td>they</td>\n",
       "      <td>responded</td>\n",
       "      <td>to</td>\n",
       "      <td>the</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS</th>\n",
       "      <td>NNS</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VBN</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>TO</td>\n",
       "      <td>VB</td>\n",
       "      <td>DT</td>\n",
       "      <td>...</td>\n",
       "      <td>NN</td>\n",
       "      <td>.</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NNS</td>\n",
       "      <td>VBD</td>\n",
       "      <td>PRP</td>\n",
       "      <td>VBD</td>\n",
       "      <td>TO</td>\n",
       "      <td>DT</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tag</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-geo</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-gpe</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 1048575 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1              2            3            4        \\\n",
       "Sentence #  Sentence: 1  Sentence: 1    Sentence: 1  Sentence: 1  Sentence: 1   \n",
       "Word          Thousands           of  demonstrators         have      marched   \n",
       "POS                 NNS           IN            NNS          VBP          VBN   \n",
       "Tag                   O            O              O            O            O   \n",
       "\n",
       "                5            6            7            8            9        \\\n",
       "Sentence #  Sentence: 1  Sentence: 1  Sentence: 1  Sentence: 1  Sentence: 1   \n",
       "Word            through       London           to      protest          the   \n",
       "POS                  IN          NNP           TO           VB           DT   \n",
       "Tag                   O        B-geo            O            O            O   \n",
       "\n",
       "            ...          1048565          1048566          1048567  \\\n",
       "Sentence #  ...  Sentence: 47958  Sentence: 47958  Sentence: 47959   \n",
       "Word        ...           impact                .           Indian   \n",
       "POS         ...               NN                .               JJ   \n",
       "Tag         ...                O                O            B-gpe   \n",
       "\n",
       "                    1048568          1048569          1048570  \\\n",
       "Sentence #  Sentence: 47959  Sentence: 47959  Sentence: 47959   \n",
       "Word                 forces             said             they   \n",
       "POS                     NNS              VBD              PRP   \n",
       "Tag                       O                O                O   \n",
       "\n",
       "                    1048571          1048572          1048573          1048574  \n",
       "Sentence #  Sentence: 47959  Sentence: 47959  Sentence: 47959  Sentence: 47959  \n",
       "Word              responded               to              the           attack  \n",
       "POS                     VBD               TO               DT               NN  \n",
       "Tag                       O                O                O                O  \n",
       "\n",
       "[4 rows x 1048575 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47959, 35178, 42, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get a deeper understanding of the data we are dealing with and the total number\n",
    "# of annotated tags, we can use the following code.\n",
    "df['Sentence #'].nunique(), df.Word.nunique(), df.POS.nunique(), df.Tag.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 47959 sentences that contain 35178 unique words.\n",
    "\n",
    "#### These sentences have a total of 42 unique POS tags and 17 unique NER tags in total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag Distribution\n",
    "\n",
    "The GMB dataset utilizes IOB tagging or _Inside, Outside Beginning_. IOB is a common tagging format for tagging tokens which we have discussed earlier. To refresh your memory:\n",
    "\n",
    "+ __I- prefix__ before a tag indicates that the tag is inside a chunk.\n",
    "+ __B- prefix__ before a tag indicates that the tag is the beginning of a chunk.\n",
    "+ __O-  tag__ indicates that a token belongs to no chunk (outside).\n",
    "\n",
    "The tags in this dataset are explained as follows:\n",
    "\n",
    "+ __geo__ = Geographical Entity\n",
    "+ __org__ = Organization\n",
    "+ __per__ = Person\n",
    "+ __gpe__ = Geopolitical Entity\n",
    "+ __tim__ = Time indicator\n",
    "+ __art__ = Artifact\n",
    "+ __eve__ = Event\n",
    "+ __nat__ = Natural Phenomenon\n",
    "\n",
    "Anything outside these classes is termed as other, denoted as __O__. \n",
    "\n",
    "The following output shows the unbalanced distribution of different tags in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O        887908\n",
       "B-geo     37644\n",
       "B-tim     20333\n",
       "B-org     20143\n",
       "I-per     17251\n",
       "B-per     16990\n",
       "I-org     16784\n",
       "B-gpe     15870\n",
       "I-geo      7414\n",
       "I-tim      6528\n",
       "B-art       402\n",
       "B-eve       308\n",
       "I-art       297\n",
       "I-eve       253\n",
       "B-nat       201\n",
       "I-gpe       198\n",
       "I-nat        51\n",
       "Name: Tag, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Tag.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Random Fields\n",
    "\n",
    "As mentioned above, NER belongs to sequence modeling class of problems. There are different algorithms to tackle sequence modeling, __CRF__ or _Conditional Random Fields_ are one such example. CRFs are proven to perform extremely well on NER and related domains. In this notebook, we will attempt at developing our own NER based on CRFs.\n",
    "\n",
    "---\n",
    "\n",
    "__Question__: What is a CRF and how does it work?\n",
    "\n",
    "__Wikipedia__ :  CRF is an undirected graphical model whose nodes can be divided into exactly two disjoint sets $X$ and $Y$, the observed and output variables, respectively; the conditional distribution $p(Y|X)$ is then modeled.\n",
    "\n",
    "For more details, checkout the paper [__Conditional Random Fields: Probabilistic Models\n",
    "for Segmenting and Labeling Sequence Data__](https://repository.upenn.edu/cgi/viewcontent.cgi?article=1162&context=cis_papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "CRF trains upon sequence of input data to learn transitions from one state (label) to another. \n",
    "To enable such an algorithm, we need to define features which take into account different transitions. \n",
    "In the function ```word2features()``` below, we transform each word into a feature dictionary depicting the following attributes or features:\n",
    "\n",
    "+ lower case of word\n",
    "+ suffix containing last 3 characters\n",
    "+ suffix containing last 2 characters\n",
    "+ flags to determine upper-case, title-case, numeric data and POS tag\n",
    "\n",
    "We also attach attributes related to previous and next words or tags to determine beginning of sentence (BOS) or end of sentence (EOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let’s now define a function to extract our word token, POS tag, and NER tag triplets from sentences. \n",
    "# We will be applying this to all our input sentences\n",
    "agg_func = lambda s: [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(), \n",
    "                                                   s['POS'].values.tolist(), \n",
    "                                                   s['Tag'].values.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby('Sentence #').apply(agg_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')])]\n"
     ]
    }
   ],
   "source": [
    "print(grouped_df[grouped_df.index == 'Sentence: 1'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47959,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Thousands', 'NNS', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('demonstrators', 'NNS', 'O'),\n",
       " ('have', 'VBP', 'O'),\n",
       " ('marched', 'VBN', 'O'),\n",
       " ('through', 'IN', 'O'),\n",
       " ('London', 'NNP', 'B-geo'),\n",
       " ('to', 'TO', 'O'),\n",
       " ('protest', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('war', 'NN', 'O'),\n",
       " ('in', 'IN', 'O'),\n",
       " ('Iraq', 'NNP', 'B-geo'),\n",
       " ('and', 'CC', 'O'),\n",
       " ('demand', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('withdrawal', 'NN', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('British', 'JJ', 'B-gpe'),\n",
       " ('troops', 'NNS', 'O'),\n",
       " ('from', 'IN', 'O'),\n",
       " ('that', 'DT', 'O'),\n",
       " ('country', 'NN', 'O'),\n",
       " ('.', '.', 'O')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now view a sample annotated sentence from our dataset with the following code.\n",
    "sentences = [s for s in grouped_df]\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bias': 1.0,\n",
       "  'word.lower()': 'through',\n",
       "  'word[-3:]': 'ugh',\n",
       "  'word[-2:]': 'gh',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'IN',\n",
       "  'postag[:2]': 'IN',\n",
       "  'BOS': True,\n",
       "  '+1:word.lower()': 'london',\n",
       "  '+1:word.istitle()': True,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'NNP',\n",
       "  '+1:postag[:2]': 'NN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'london',\n",
       "  'word[-3:]': 'don',\n",
       "  'word[-2:]': 'on',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': True,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'NNP',\n",
       "  'postag[:2]': 'NN',\n",
       "  '-1:word.lower()': 'through',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'IN',\n",
       "  '-1:postag[:2]': 'IN',\n",
       "  'EOS': True}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The preceding output shows a standard tokenized sentence with POS and NER tags. Let’s look at how each annotated tokenized\n",
    "# sentence can be used for our feature engineering with the function we defined earlier.\n",
    "sent2features(sentences[0][5:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-geo']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2labels(sentences[0][5:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Train and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35969,), (11990,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([sent2features(s) for s in sentences])\n",
    "y = np.array([sent2labels(s) for s in sentences])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_train.shape, X_test.shape\n",
    "\n",
    "# It is now time to start training our model. For this, we use sklearn-crfsuite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Models with sklearn-crfsuite\n",
    "\n",
    "__`sklearn-crfsuite`__ is a thin [CRFsuite (python-crfsuite)](https://github.com/scrapinghub/python-crfsuite) wrapper which provides scikit-learn-compatible sklearn_crfsuite.CRF estimator: you can use e.g. scikit-learn model selection utilities (cross-validation, hyperparameter optimization) with it, or save/load CRF models using joblib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn-crfsuite\n",
      "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
      "Collecting python-crfsuite>=0.8.3\n",
      "  Downloading python_crfsuite-0.9.7-cp37-cp37m-win_amd64.whl (154 kB)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.7-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: tqdm>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sklearn-crfsuite) (4.42.1)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from sklearn-crfsuite) (1.14.0)\n",
      "Installing collected packages: python-crfsuite, tabulate, sklearn-crfsuite\n",
      "Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6 tabulate-0.8.7\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn-crfsuite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model!\n",
    "\n",
    "Train the model using the default configurations mentioned in the [sklearn-crfsuite API docs](https://sklearn-crfsuite.readthedocs.io/en/latest/api.html)\n",
    "\n",
    "\n",
    "- __algorithm:__ the training algorithm. We use [L-BFGS](https://en.wikipedia.org/wiki/Limited-memory_BFGS) for gradient descent for optimization and getting model parameters\n",
    "- __c1:__ Coefficient for Lasso (L1) regularization\n",
    "- __c2:__ Coefficient for Ridge (L2) regularization\n",
    "- __all_possible_transitions:__ Specify whether CRFsuite generates transition features that do not even occur in the training data\n",
    "\n",
    "\n",
    "__Note:__ If the model is taking too long to train, you can load up the pre-trained model using the code after the training cells and use that for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs',\n",
    "                           c1=0.1,\n",
    "                           c2=0.1,\n",
    "                           max_iterations=100,\n",
    "                           all_possible_transitions=True,\n",
    "                           verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|███████████████████████████████████████| 35969/35969 [00:15<00:00, 2384.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 133629\n",
      "Seconds required: 3.486\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.100000\n",
      "c2: 0.100000\n",
      "num_memories: 6\n",
      "max_iterations: 100\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=4.01  loss=1264028.26 active=132637 feature_norm=1.00\n",
      "Iter 2   time=3.99  loss=994059.01 active=131294 feature_norm=4.42\n",
      "Iter 3   time=2.00  loss=776413.87 active=125970 feature_norm=3.87\n",
      "Iter 4   time=11.46 loss=422143.40 active=127018 feature_norm=3.24\n",
      "Iter 5   time=2.11  loss=355775.44 active=129029 feature_norm=4.04\n",
      "Iter 6   time=2.23  loss=264125.22 active=124046 feature_norm=6.10\n",
      "Iter 7   time=2.36  loss=222304.71 active=117183 feature_norm=7.69\n",
      "Iter 8   time=2.21  loss=197827.17 active=110838 feature_norm=8.75\n",
      "Iter 9   time=2.09  loss=176877.92 active=105650 feature_norm=10.41\n",
      "Iter 10  time=2.09  loss=158997.61 active=103459 feature_norm=11.60\n",
      "Iter 11  time=2.10  loss=146328.53 active=100247 feature_norm=13.41\n",
      "Iter 12  time=2.09  loss=137671.14 active=98635 feature_norm=14.69\n",
      "Iter 13  time=2.11  loss=130471.62 active=97462 feature_norm=15.45\n",
      "Iter 14  time=2.09  loss=118841.84 active=94124 feature_norm=17.81\n",
      "Iter 15  time=2.11  loss=112928.42 active=92178 feature_norm=20.21\n",
      "Iter 16  time=2.09  loss=105499.44 active=91978 feature_norm=22.27\n",
      "Iter 17  time=2.08  loss=101994.76 active=91940 feature_norm=23.34\n",
      "Iter 18  time=2.10  loss=96362.28 active=89453 feature_norm=26.63\n",
      "Iter 19  time=2.09  loss=90647.28 active=89021 feature_norm=28.85\n",
      "Iter 20  time=2.10  loss=85521.13 active=87547 feature_norm=32.66\n",
      "Iter 21  time=2.11  loss=81239.75 active=87184 feature_norm=36.05\n",
      "Iter 22  time=2.09  loss=77980.98 active=86649 feature_norm=39.45\n",
      "Iter 23  time=2.08  loss=75036.81 active=86300 feature_norm=41.33\n",
      "Iter 24  time=2.10  loss=70028.55 active=82924 feature_norm=47.18\n",
      "Iter 25  time=4.16  loss=67859.30 active=82277 feature_norm=51.09\n",
      "Iter 26  time=2.10  loss=64640.62 active=81815 feature_norm=54.83\n",
      "Iter 27  time=2.09  loss=61783.61 active=80545 feature_norm=60.05\n",
      "Iter 28  time=2.08  loss=59095.29 active=79506 feature_norm=66.46\n",
      "Iter 29  time=2.09  loss=56799.57 active=79733 feature_norm=70.47\n",
      "Iter 30  time=2.09  loss=54812.68 active=79492 feature_norm=75.32\n",
      "Iter 31  time=2.28  loss=52807.07 active=78965 feature_norm=80.24\n",
      "Iter 32  time=2.28  loss=50790.16 active=78225 feature_norm=88.16\n",
      "Iter 33  time=2.15  loss=49548.49 active=78456 feature_norm=90.54\n",
      "Iter 34  time=2.12  loss=48303.45 active=78007 feature_norm=94.98\n",
      "Iter 35  time=2.12  loss=46171.65 active=76442 feature_norm=106.16\n",
      "Iter 36  time=2.11  loss=45327.99 active=75732 feature_norm=115.55\n",
      "Iter 37  time=2.08  loss=43822.08 active=75408 feature_norm=118.88\n",
      "Iter 38  time=2.09  loss=42688.21 active=74715 feature_norm=125.25\n",
      "Iter 39  time=2.09  loss=41275.71 active=73716 feature_norm=139.21\n",
      "Iter 40  time=2.08  loss=40047.55 active=73576 feature_norm=147.46\n",
      "Iter 41  time=2.12  loss=39265.28 active=73554 feature_norm=151.63\n",
      "Iter 42  time=2.12  loss=38403.33 active=72721 feature_norm=159.70\n",
      "Iter 43  time=2.34  loss=37608.69 active=72627 feature_norm=165.70\n",
      "Iter 44  time=2.14  loss=36823.99 active=71771 feature_norm=172.98\n",
      "Iter 45  time=2.11  loss=36326.35 active=70178 feature_norm=184.40\n",
      "Iter 46  time=2.09  loss=35883.80 active=69283 feature_norm=186.01\n",
      "Iter 47  time=2.11  loss=35560.99 active=68923 feature_norm=190.20\n",
      "Iter 48  time=2.10  loss=35404.76 active=67538 feature_norm=199.98\n",
      "Iter 49  time=2.11  loss=35012.55 active=67985 feature_norm=200.64\n",
      "Iter 50  time=2.10  loss=34929.44 active=68033 feature_norm=200.67\n",
      "Iter 51  time=2.08  loss=34693.21 active=67122 feature_norm=201.84\n",
      "Iter 52  time=4.14  loss=34629.25 active=66830 feature_norm=201.25\n",
      "Iter 53  time=2.09  loss=34459.64 active=66761 feature_norm=202.56\n",
      "Iter 54  time=2.10  loss=34344.14 active=66577 feature_norm=203.72\n",
      "Iter 55  time=2.10  loss=34165.12 active=66051 feature_norm=205.31\n",
      "Iter 56  time=2.09  loss=34162.67 active=64890 feature_norm=206.81\n",
      "Iter 57  time=2.13  loss=33943.85 active=65312 feature_norm=207.03\n",
      "Iter 58  time=2.10  loss=33886.19 active=64897 feature_norm=207.50\n",
      "Iter 59  time=2.10  loss=33780.88 active=64020 feature_norm=208.77\n",
      "Iter 60  time=2.10  loss=33666.08 active=63580 feature_norm=209.40\n",
      "Iter 61  time=2.10  loss=33571.12 active=63159 feature_norm=210.40\n",
      "Iter 62  time=2.34  loss=33488.40 active=63013 feature_norm=210.87\n",
      "Iter 63  time=2.23  loss=33397.52 active=62694 feature_norm=211.68\n",
      "Iter 64  time=2.11  loss=33317.69 active=62488 feature_norm=212.22\n",
      "Iter 65  time=2.11  loss=33247.01 active=62238 feature_norm=212.80\n",
      "Iter 66  time=2.08  loss=33173.26 active=62029 feature_norm=213.27\n",
      "Iter 67  time=2.10  loss=33108.73 active=61781 feature_norm=213.91\n",
      "Iter 68  time=2.11  loss=33052.25 active=61575 feature_norm=214.27\n",
      "Iter 69  time=2.08  loss=32996.19 active=61366 feature_norm=214.76\n",
      "Iter 70  time=2.09  loss=32941.28 active=61153 feature_norm=215.10\n",
      "Iter 71  time=2.08  loss=32894.22 active=60966 feature_norm=215.53\n",
      "Iter 72  time=2.10  loss=32853.09 active=60815 feature_norm=215.78\n",
      "Iter 73  time=2.07  loss=32814.22 active=60658 feature_norm=216.15\n",
      "Iter 74  time=2.10  loss=32778.22 active=60513 feature_norm=216.37\n",
      "Iter 75  time=2.09  loss=32743.64 active=60336 feature_norm=216.67\n",
      "Iter 76  time=2.09  loss=32711.92 active=60185 feature_norm=216.86\n",
      "Iter 77  time=2.11  loss=32682.08 active=60090 feature_norm=217.11\n",
      "Iter 78  time=2.09  loss=32654.10 active=59916 feature_norm=217.27\n",
      "Iter 79  time=2.09  loss=32627.76 active=59768 feature_norm=217.54\n",
      "Iter 80  time=2.10  loss=32603.13 active=59701 feature_norm=217.65\n",
      "Iter 81  time=2.11  loss=32580.63 active=59546 feature_norm=217.85\n",
      "Iter 82  time=2.08  loss=32559.76 active=59413 feature_norm=217.96\n",
      "Iter 83  time=2.08  loss=32538.88 active=59278 feature_norm=218.17\n",
      "Iter 84  time=2.14  loss=32520.71 active=59165 feature_norm=218.27\n",
      "Iter 85  time=2.12  loss=32501.10 active=59088 feature_norm=218.47\n",
      "Iter 86  time=2.09  loss=32484.14 active=58988 feature_norm=218.56\n",
      "Iter 87  time=2.08  loss=32467.58 active=58909 feature_norm=218.71\n",
      "Iter 88  time=2.16  loss=32452.86 active=58808 feature_norm=218.80\n",
      "Iter 89  time=2.08  loss=32437.92 active=58717 feature_norm=218.98\n",
      "Iter 90  time=2.10  loss=32424.99 active=58671 feature_norm=219.06\n",
      "Iter 91  time=2.13  loss=32411.01 active=58618 feature_norm=219.21\n",
      "Iter 92  time=2.09  loss=32399.15 active=58552 feature_norm=219.29\n",
      "Iter 93  time=2.08  loss=32386.63 active=58490 feature_norm=219.40\n",
      "Iter 94  time=2.08  loss=32375.74 active=58448 feature_norm=219.48\n",
      "Iter 95  time=2.10  loss=32364.54 active=58374 feature_norm=219.60\n",
      "Iter 96  time=2.07  loss=32354.96 active=58381 feature_norm=219.68\n",
      "Iter 97  time=2.08  loss=32344.27 active=58343 feature_norm=219.80\n",
      "Iter 98  time=2.09  loss=32335.08 active=58304 feature_norm=219.87\n",
      "Iter 99  time=2.07  loss=32324.92 active=58249 feature_norm=219.98\n",
      "Iter 100 time=2.09  loss=32316.67 active=58226 feature_norm=220.04\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 228.530\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 58226 (133629)\n",
      "Number of active attributes: 29279 (90250)\n",
      "Number of active labels: 17 (17)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.095\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=0.1, c2=0.1,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the following to load our pre-trained model if training above takes a lot of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ner_model.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(crf, 'ner_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = joblib.load('ner_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "Let's evaluate our model performance for NER Tagging on the test data now!\n",
    "\n",
    "Try playing around with the following cells and observe the overall model performance.\n",
    "\n",
    "We use standard classification metrics like precision, recall and f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'tag'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-64b5cfc31b17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn_crfsuite\\estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m         \"\"\"\n\u001b[1;32m--> 350\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_single\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_single\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn_crfsuite\\estimator.py\u001b[0m in \u001b[0;36mpredict_single\u001b[1;34m(self, xseq)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \"\"\"\n\u001b[1;32m--> 367\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtagger_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_marginals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'tag'"
     ]
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "print(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'B-per', 'I-per', 'O', 'B-org', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_crfsuite import metrics as crf_metrics\n",
    "\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-org       0.81      0.73      0.77      5116\n",
      "       B-per       0.85      0.84      0.84      4239\n",
      "       I-per       0.85      0.90      0.88      4273\n",
      "       B-geo       0.86      0.91      0.89      9403\n",
      "       I-geo       0.81      0.80      0.81      1826\n",
      "       B-tim       0.93      0.89      0.91      5095\n",
      "       I-org       0.82      0.79      0.80      4195\n",
      "       B-gpe       0.97      0.94      0.96      3961\n",
      "       I-tim       0.84      0.81      0.82      1604\n",
      "       B-nat       0.50      0.24      0.32        55\n",
      "       B-eve       0.51      0.33      0.40        80\n",
      "       B-art       0.36      0.14      0.20       102\n",
      "       I-art       0.24      0.07      0.10        90\n",
      "       I-eve       0.45      0.19      0.27        74\n",
      "       I-gpe       0.86      0.53      0.66        36\n",
      "       I-nat       0.57      0.22      0.32        18\n",
      "\n",
      "   micro avg       0.86      0.85      0.86     40167\n",
      "   macro avg       0.70      0.58      0.62     40167\n",
      "weighted avg       0.86      0.85      0.85     40167\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(crf_metrics.flat_classification_report(y_test, y_pred, labels=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have intentially left out the ___Others___ tag to understand the performance of model on the remaining tags. The above evaluation statistics showcase a model which seems to have learnt the transitions quite well giving us an overall F1-score of 85%!\n",
    "\n",
    "#### We can achieve even better results by fine tuning the feature engineering step along with hyper-parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-End NER Tagger with trained NER Model\n",
    "\n",
    "There is no fun (or value!) if we cannot use our model to tag new sentences in the future assuming we would want to put this model in production. Let's try and build an end-to-end workflow to perform NER Tagging on our sample document. First we perform NER tagging with SpaCy to remind you how it looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Sample Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Three more countries have joined an “international grand committee” of parliaments, adding to calls for Facebook’s boss, Mark Zuckerberg, to give evidence on misinformation to the coalition. Brazil, Latvia and Singapore bring the total to eight different parliaments across the world, with plans to send representatives to London on 27 November with the intention of hearing from Zuckerberg. Since the Cambridge Analytica scandal broke, the Facebook chief has only appeared in front of two legislatures: the American Senate and House of Representatives, and the European parliament. Facebook has consistently rebuffed attempts from others, including the UK and Canadian parliaments, to hear from Zuckerberg. He added that an article in the New York Times on Thursday, in which the paper alleged a pattern of behaviour from Facebook to “delay, deny and deflect” negative news stories, “raises further questions about how recent data breaches were allegedly dealt with within Facebook.”'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"\"\"Three more countries have joined an “international grand committee” of parliaments, adding to calls for \n",
    "Facebook’s boss, Mark Zuckerberg, to give evidence on misinformation to the coalition. Brazil, Latvia and Singapore \n",
    "bring the total to eight different parliaments across the world, with plans to send representatives to London on 27 \n",
    "November with the intention of hearing from Zuckerberg. Since the Cambridge Analytica scandal broke, the Facebook chief \n",
    "has only appeared in front of two legislatures: the American Senate and House of Representatives, and the European parliament. \n",
    "Facebook has consistently rebuffed attempts from others, including the UK and Canadian parliaments, to hear from Zuckerberg. \n",
    "He added that an article in the New York Times on Thursday, in which the paper alleged a pattern of behaviour from Facebook \n",
    "to “delay, deny and deflect” negative news stories, “raises further questions about how recent data breaches were allegedly \n",
    "dealt with within Facebook.”\n",
    "\"\"\"\n",
    "\n",
    "text = re.sub(r'\\n', '', text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"οκτώ 8 Παρασκευή 3 Νοεμβρίου 2018 Zuckeberg Ευρωπαϊκή Ένωση: αποτελείται από 27 μέλη, τα οποία συναντιούνται κατ' ιδίαν για να συμφωνήσουν σχετικά με τις κοινές θέσεις τους και αντιπροσωπεύεται από τη χώρα που έχει την προεδρία. Σημειώνεται ότι η Ευρωπαϊκή Ένωση είναι η πιο ενεργή ομάδα όσον αφορά στις διαπραγματεύσεις για την προστασία του περιβάλλοντος και πιέζει συνεχώς για τη λήψη αυστηρών μέτρων. Σημειώνεται ότι την περίοδο των διαπραγματεύσεων η Ευρωπαϊκή Ένωση αποτελούνταν από 15 κράτη μέλη, με αυτά όμως συμμάχησαν και τα 12 νέα μέλη της διεύρυνσης.«Λέσχη του Άνθρακα» (“Carbon Club”): περιλαμβάνει τις χώρες «JUSCANZ» (από τα αρχικά των χωρών Ιαπωνία, ΗΠΑ, Καναδάς, Αυστραλία, Νέα Ζηλανδία στα Αγγλικά), τις χώρες μέλη του ΟΠΕΚ, τη Ρωσία και τη Νορβηγία, στις οποίες γενικά τα συμφέροντά τους θίγονται από το Πρωτόκολλο του Κιότο (είτε επειδή θα πρέπει να μειώσουν την παραγωγή τους είτε επειδή προτείνεται η στροφή προς διαφορετικά καύσιμα) και κατά συνέπεια αντιτίθενται στην καθιέρωση των δικαιωμάτων και στη λήψη αυστηρών μέτρων.Συμμαχία των Μικρών Νησιωτικών Κρατών (AOSIS): είναι ένας συνασπισμός περίπου 43 μικρών νησιωτικών κρατών, τα οποία είναι ιδιαίτερα ευάλωτα στην άνοδο της στάθμης της θάλασσας. Τα κράτη αυτά κινδυνεύουν να εξαφανιστούν από το χάρτη εξαιτίας του μικρού τους υψομέτρου σε σχέση με το επίπεδο της θάλασσας και επομένως απειλείται άμεσα η ίδια τους η επιβίωση. Οι χώρες της ομάδας αυτής ήταν μάλιστα οι πρώτες που πρότειναν ένα σχέδιο κειμένου κατά τη διάρκεια των διαπραγματεύσεων του πρωτοκόλλου του Κιότο ζητώντας μία μείωση στις εκπομπές διοξειδίου του άνθρακα της τάξης του 20% έως το 2005 σε σχέση με τα επίπεδα του 1990.Λιγότερο αναπτυγμένες χώρες: πρόκειται για 48 χώρες, οι οποίες συμμετείχαν όλο και πιο ενεργά στη διαδικασία των διαπραγματεύσεων για την αλλαγή του κλίματος, συχνά για να υπερασπιστούν τα ιδιαίτερα συμφέροντά τους και την εύθραυστη οικονομία τους, όπως για παράδειγμα την παροχή μέτρων για να μπορέσουν να προσαρμοστούν στην αλλαγή του κλίματος και να μην είναι τόσο ευάλωτες.Ομάδα των 77 (G-77): πρόκειται για εκείνες τις αναπτυσσόμενες χώρες που είναι αναδυόμενες, όπως η Ινδία και η Κίνα, που θεωρούν ότι βρίσκονται σε τροχιά ανάπτυξης και ότι είναι εις βάρος τους να δεσμευτούν να περιορίσουν τις εκπομπές τους. Η δε απαίτηση των βιομηχανικών χωρών (που είναι κυρίως υπεύθυνες για τις μεγαλύτερες εκπομπές αερίων του θερμοκηπίου παγκοσμίως) να αντιμετωπιστούν επί ίσοις όροις με τις αναπτυσσόμενες χώρες τους φαίνεται άδικη και παράλογη.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"οκτώ 8 Παρασκευή 3 Νοεμβρίου 2018 Zuckeberg Ευρωπαϊκή Ένωση: αποτελείται από 27 μέλη, τα οποία συναντιούνται κατ' ιδίαν για να συμφωνήσουν σχετικά με τις κοινές θέσεις τους και αντιπροσωπεύεται από τη χώρα που έχει την προεδρία. Σημειώνεται ότι η Ευρωπαϊκή Ένωση είναι η πιο ενεργή ομάδα όσον αφορά στις διαπραγματεύσεις για την προστασία του περιβάλλοντος και πιέζει συνεχώς για τη λήψη αυστηρών μέτρων. Σημειώνεται ότι την περίοδο των διαπραγματεύσεων η Ευρωπαϊκή Ένωση αποτελούνταν από 15 κράτη μέλη, με αυτά όμως συμμάχησαν και τα 12 νέα μέλη της διεύρυνσης.\n",
    "«Λέσχη του Άνθρακα» (“Carbon Club”): περιλαμβάνει τις χώρες «JUSCANZ» (από τα αρχικά των χωρών Ιαπωνία, ΗΠΑ, Καναδάς, Αυστραλία, Νέα Ζηλανδία στα Αγγλικά), τις χώρες μέλη του ΟΠΕΚ, τη Ρωσία και τη Νορβηγία, στις οποίες γενικά τα συμφέροντά τους θίγονται από το Πρωτόκολλο του Κιότο (είτε επειδή θα πρέπει να μειώσουν την παραγωγή τους είτε επειδή προτείνεται η στροφή προς διαφορετικά καύσιμα) και κατά συνέπεια αντιτίθενται στην καθιέρωση των δικαιωμάτων και στη λήψη αυστηρών μέτρων.\n",
    "Συμμαχία των Μικρών Νησιωτικών Κρατών (AOSIS): είναι ένας συνασπισμός περίπου 43 μικρών νησιωτικών κρατών, τα οποία είναι ιδιαίτερα ευάλωτα στην άνοδο της στάθμης της θάλασσας. Τα κράτη αυτά κινδυνεύουν να εξαφανιστούν από το χάρτη εξαιτίας του μικρού τους υψομέτρου σε σχέση με το επίπεδο της θάλασσας και επομένως απειλείται άμεσα η ίδια τους η επιβίωση. Οι χώρες της ομάδας αυτής ήταν μάλιστα οι πρώτες που πρότειναν ένα σχέδιο κειμένου κατά τη διάρκεια των διαπραγματεύσεων του πρωτοκόλλου του Κιότο ζητώντας μία μείωση στις εκπομπές διοξειδίου του άνθρακα της τάξης του 20% έως το 2005 σε σχέση με τα επίπεδα του 1990.\n",
    "Λιγότερο αναπτυγμένες χώρες: πρόκειται για 48 χώρες, οι οποίες συμμετείχαν όλο και πιο ενεργά στη διαδικασία των διαπραγματεύσεων για την αλλαγή του κλίματος, συχνά για να υπερασπιστούν τα ιδιαίτερα συμφέροντά τους και την εύθραυστη οικονομία τους, όπως για παράδειγμα την παροχή μέτρων για να μπορέσουν να προσαρμοστούν στην αλλαγή του κλίματος και να μην είναι τόσο ευάλωτες.\n",
    "Ομάδα των 77 (G-77): πρόκειται για εκείνες τις αναπτυσσόμενες χώρες που είναι αναδυόμενες, όπως η Ινδία και η Κίνα, που θεωρούν ότι βρίσκονται σε τροχιά ανάπτυξης και ότι είναι εις βάρος τους να δεσμευτούν να περιορίσουν τις εκπομπές τους. Η δε απαίτηση των βιομηχανικών χωρών (που είναι κυρίως υπεύθυνες για τις μεγαλύτερες εκπομπές αερίων του θερμοκηπίου παγκοσμίως) να αντιμετωπιστούν επί ίσοις όροις με τις αναπτυσσόμενες χώρες τους φαίνεται άδικη και παράλογη.\n",
    "\"\"\"\n",
    "\n",
    "text = re.sub(r'\\n', '', text)\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER Tagging with SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">οκτώ 8 Παρασκευή 3 Νοεμβρίου 2018 Zuckeberg \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ευρωπαϊκή Ένωση\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ": αποτελείται από 27 μέλη, τα οποία συναντιούνται κατ' ιδίαν για να συμφωνήσουν σχετικά με τις κοινές θέσεις τους και αντιπροσωπεύεται από τη χώρα που έχει την προεδρία. Σημειώνεται ότι η \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ευρωπαϊκή Ένωση\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " είναι η πιο ενεργή ομάδα όσον αφορά στις διαπραγματεύσεις για την προστασία του περιβάλλοντος και πιέζει συνεχώς για τη λήψη αυστηρών μέτρων. Σημειώνεται ότι την περίοδο των διαπραγματεύσεων η \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ευρωπαϊκή Ένωση\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " αποτελούνταν από 15 κράτη μέλη, με αυτά όμως συμμάχησαν και τα 12 νέα μέλη της διεύρυνσης.«Λέσχη του Άνθρακα» (“\n",
       "<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Carbon Club\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n",
       "</mark>\n",
       "”): περιλαμβάνει τις χώρες «\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    JUSCANZ\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "» (από τα αρχικά των χωρών \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ιαπωνία\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ΗΠΑ\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Καναδάς\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Αυστραλία\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Νέα Ζηλανδία\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " στα Αγγλικά), τις χώρες μέλη του \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ΟΠΕΚ\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", τη \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ρωσία\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " και τη \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Νορβηγία\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", στις οποίες γενικά τα συμφέροντά τους θίγονται από το \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Πρωτόκολλο του Κιότο\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " (είτε επειδή θα πρέπει να μειώσουν την παραγωγή τους είτε επειδή προτείνεται η στροφή προς διαφορετικά καύσιμα) και κατά συνέπεια αντιτίθενται στην καθιέρωση των δικαιωμάτων και στη λήψη αυστηρών μέτρων.Συμμαχία των Μικρών \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Νησιωτικών Κρατών\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " (\n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    AOSIS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       "): είναι ένας συνασπισμός περίπου 43 μικρών νησιωτικών κρατών, τα οποία είναι ιδιαίτερα ευάλωτα στην άνοδο της στάθμης της θάλασσας. Τα κράτη αυτά κινδυνεύουν να εξαφανιστούν από το χάρτη εξαιτίας του μικρού τους υψομέτρου σε σχέση με το επίπεδο της θάλασσας και επομένως απειλείται άμεσα η ίδια τους η επιβίωση. Οι χώρες της ομάδας αυτής ήταν μάλιστα οι πρώτες που πρότειναν ένα σχέδιο κειμένου κατά τη διάρκεια των διαπραγματεύσεων του πρωτοκόλλου του \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Κιότο\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " ζητώντας μία μείωση στις εκπομπές διοξειδίου του άνθρακα της τάξης του 20% έως το 2005 σε σχέση με τα επίπεδα του 1990.Λιγότερο αναπτυγμένες χώρες: πρόκειται για 48 χώρες, οι οποίες συμμετείχαν όλο και πιο ενεργά στη διαδικασία των διαπραγματεύσεων για την αλλαγή του κλίματος, συχνά για να υπερασπιστούν τα ιδιαίτερα συμφέροντά τους και την εύθραυστη οικονομία τους, όπως για παράδειγμα την παροχή μέτρων για να μπορέσουν να προσαρμοστούν στην αλλαγή του κλίματος και να μην είναι τόσο ευάλωτες.Ομάδα των 77 (G-77): πρόκειται για εκείνες τις αναπτυσσόμενες χώρες που είναι αναδυόμενες, όπως η \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ινδία\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " και η \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Κίνα\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", που θεωρούν ότι βρίσκονται σε τροχιά ανάπτυξης και ότι είναι εις βάρος τους να δεσμευτούν να περιορίσουν τις εκπομπές τους. Η δε απαίτηση των βιομηχανικών χωρών (που είναι κυρίως υπεύθυνες για τις μεγαλύτερες εκπομπές αερίων του θερμοκηπίου παγκοσμίως) να αντιμετωπιστούν επί ίσοις όροις με τις αναπτυσσόμενες χώρες τους φαίνεται άδικη και παράλογη.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "import el_core_news_md\n",
    "nlp = el_core_news_md.load()\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "text_nlp = nlp(text)\n",
    "displacy.render(text_nlp, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Step 1\n",
    "\n",
    "- Tokenize Text\n",
    "- POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('οκτώ', 'RB'),\n",
       " ('8', 'CD'),\n",
       " ('Παρασκευή', 'JJ'),\n",
       " ('3', 'CD'),\n",
       " ('Νοεμβρίου', 'JJ'),\n",
       " ('2018', 'CD'),\n",
       " ('Zuckeberg', 'NNP'),\n",
       " ('Ευρωπαϊκή', 'NNP'),\n",
       " ('Ένωση', 'NN'),\n",
       " (':', ':'),\n",
       " ('αποτελείται', 'JJ'),\n",
       " ('από', '$'),\n",
       " ('27', 'CD'),\n",
       " ('μέλη', 'NNP'),\n",
       " (',', ','),\n",
       " ('τα', 'NNP'),\n",
       " ('οποία', 'NNP'),\n",
       " ('συναντιούνται', 'NNP'),\n",
       " ('κατ', 'NNP'),\n",
       " (\"'\", 'POS')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "text_tokens = nltk.word_tokenize(text)\n",
    "text_pos = nltk.pos_tag(text_tokens)\n",
    "text_pos[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Step 2\n",
    "- Extract Features from the POS tagged text document\n",
    "- Hint: Use `sent2features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sent2features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-9710627f408e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msent2features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_pos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sent2features' is not defined"
     ]
    }
   ],
   "source": [
    "features = [sent2features(text_pos)]\n",
    "features[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Step 3\n",
    "- Use the CRF Model `crf` to predict on the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'tag'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-0d3a1efa27f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdoc_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdoc_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn_crfsuite\\estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m         \"\"\"\n\u001b[1;32m--> 350\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_single\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_single\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn_crfsuite\\estimator.py\u001b[0m in \u001b[0;36mpredict_single\u001b[1;34m(self, xseq)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \"\"\"\n\u001b[1;32m--> 367\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtagger_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_marginals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'tag'"
     ]
    }
   ],
   "source": [
    "labels = crf.predict(features)\n",
    "doc_labels = labels[0]\n",
    "doc_labels[10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Step 4\n",
    "- Combine text tokens with NER Tags\n",
    "- Retrieve relevant named entities from NER Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-1bfaf18783c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtext_ner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_ner\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'doc_labels' is not defined"
     ]
    }
   ],
   "source": [
    "text_ner = [(token, tag) for token, tag in zip(text_tokens, doc_labels)]\n",
    "print(text_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_entities = []\n",
    "temp_entity_name = ''\n",
    "temp_named_entity = None\n",
    "for term, tag in text_ner:\n",
    "    if tag != 'O':\n",
    "        temp_entity_name = ' '.join([temp_entity_name, term]).strip()\n",
    "        temp_named_entity = (temp_entity_name, tag)\n",
    "    else:\n",
    "        if temp_named_entity:\n",
    "            named_entities.append(temp_named_entity)\n",
    "            temp_entity_name = ''\n",
    "            temp_named_entity = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Facebook ’</td>\n",
       "      <td>I-art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mark Zuckerberg</td>\n",
       "      <td>I-per</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Latvia and Singapore</td>\n",
       "      <td>I-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>London</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27 November</td>\n",
       "      <td>I-tim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zuckerberg</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cambridge Analytica</td>\n",
       "      <td>I-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>B-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>American Senate and House of Representatives</td>\n",
       "      <td>I-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>European parliament</td>\n",
       "      <td>I-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>B-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>UK</td>\n",
       "      <td>B-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Canadian</td>\n",
       "      <td>B-gpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Zuckerberg</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>New York Times</td>\n",
       "      <td>I-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>B-tim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>B-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>B-art</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Entity    Tag\n",
       "0                                     Facebook ’  I-art\n",
       "1                                Mark Zuckerberg  I-per\n",
       "2                                         Brazil  B-geo\n",
       "3                           Latvia and Singapore  I-org\n",
       "4                                         London  B-geo\n",
       "5                                    27 November  I-tim\n",
       "6                                     Zuckerberg  B-geo\n",
       "7                            Cambridge Analytica  I-org\n",
       "8                                       Facebook  B-org\n",
       "9   American Senate and House of Representatives  I-org\n",
       "10                           European parliament  I-org\n",
       "11                                      Facebook  B-org\n",
       "12                                            UK  B-org\n",
       "13                                      Canadian  B-gpe\n",
       "14                                    Zuckerberg  B-geo\n",
       "15                                New York Times  I-org\n",
       "16                                      Thursday  B-tim\n",
       "17                                      Facebook  B-org\n",
       "18                                      Facebook  B-art"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(named_entities, columns=['Entity', 'Tag'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
