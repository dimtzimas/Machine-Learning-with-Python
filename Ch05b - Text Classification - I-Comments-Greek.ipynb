{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "import text_normalizer_el as tn # greek\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "# to prevent the model from overfitting or not generalizing well - parameter remove\n",
    "data = fetch_20newsgroups(subset='all', shuffle=True,\n",
    "                          remove=('headers', 'footers', 'quotes'))\n",
    "data_labels_map = dict(enumerate(data.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18846, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Target Label</th>\n",
       "      <th>Target Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nI am sure some bashers of Pens fans are pr...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My brother is in the market for a high-perform...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\n\\n\\tFinally you said what you dream abou...</td>\n",
       "      <td>17</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nThink!\\n\\nIt's the SCSI card doing the DMA t...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1)    I have an old Jasmine drive which I cann...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n\\nBack in high school I worked as a lab assi...</td>\n",
       "      <td>12</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n\\nAE is in Dallas...try 214/241-6060 or 214/...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\n[stuff deleted]\\n\\nOk, here's the solution t...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\n\\n\\nYeah, it's the second one.  And I believ...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\nIf a Christian means someone who believes in...</td>\n",
       "      <td>19</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  Target Label  \\\n",
       "0  \\n\\nI am sure some bashers of Pens fans are pr...            10   \n",
       "1  My brother is in the market for a high-perform...             3   \n",
       "2  \\n\\n\\n\\n\\tFinally you said what you dream abou...            17   \n",
       "3  \\nThink!\\n\\nIt's the SCSI card doing the DMA t...             3   \n",
       "4  1)    I have an old Jasmine drive which I cann...             4   \n",
       "5  \\n\\nBack in high school I worked as a lab assi...            12   \n",
       "6  \\n\\nAE is in Dallas...try 214/241-6060 or 214/...             4   \n",
       "7  \\n[stuff deleted]\\n\\nOk, here's the solution t...            10   \n",
       "8  \\n\\n\\nYeah, it's the second one.  And I believ...            10   \n",
       "9  \\nIf a Christian means someone who believes in...            19   \n",
       "\n",
       "                Target Name  \n",
       "0          rec.sport.hockey  \n",
       "1  comp.sys.ibm.pc.hardware  \n",
       "2     talk.politics.mideast  \n",
       "3  comp.sys.ibm.pc.hardware  \n",
       "4     comp.sys.mac.hardware  \n",
       "5           sci.electronics  \n",
       "6     comp.sys.mac.hardware  \n",
       "7          rec.sport.hockey  \n",
       "8          rec.sport.hockey  \n",
       "9        talk.religion.misc  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We now leverage the helper function from Scikit-Learn to fetch the required data.\n",
    "# Once we get the data, we transform this data into an easy-to-use dataframe\n",
    "corpus, target_labels, target_names = (data.data, data.target, \n",
    "                                       [data_labels_map[label] for label in data.target])\n",
    "data_df = pd.DataFrame({'Article': corpus, 'Target Label': target_labels, 'Target Name': target_names})\n",
    "print(data_df.shape)\n",
    "data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty documents: 0\n"
     ]
    }
   ],
   "source": [
    "# empty documents in our dataset and remove them\n",
    "total_nulls = data_df[data_df.Article.str.strip() == ''].shape[0]\n",
    "print(\"Empty documents:\", total_nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18301, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = data_df[~(data_df.Article.str.strip() == '')]\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['αλλα', 'αν', 'αντι', 'απο', 'αυτα', 'αυτεσ', 'αυτη', 'αυτο', 'αυτοι', 'αυτοσ', 'αυτουσ', 'αυτων', 'αἱ', 'αἳ', 'αἵ', 'αὐτόσ', 'αὐτὸς', 'αὖ', 'γάρ', 'γα', 'γα^', 'γε', 'για', 'γοῦν', 'γὰρ', \"δ'\", 'δέ', 'δή', 'δαί', 'δαίσ', 'δαὶ', 'δαὶς', 'δε', 'δεν', \"δι'\", 'διά', 'διὰ', 'δὲ', 'δὴ', 'δ’', 'εαν', 'ειμαι', 'ειμαστε', 'ειναι', 'εισαι', 'ειστε', 'εκεινα', 'εκεινεσ', 'εκεινη', 'εκεινο', 'εκεινοι', 'εκεινοσ', 'εκεινουσ', 'εκεινων', 'ενω', 'επ', 'επι', 'εἰ', 'εἰμί', 'εἰμὶ', 'εἰς', 'εἰσ', 'εἴ', 'εἴμι', 'εἴτε', 'η', 'θα', 'ισωσ', 'κ', 'καί', 'καίτοι', 'καθ', 'και', 'κατ', 'κατά', 'κατα', 'κατὰ', 'καὶ', 'κι', 'κἀν', 'κἂν', 'μέν', 'μή', 'μήτε', 'μα', 'με', 'μεθ', 'μετ', 'μετά', 'μετα', 'μετὰ', 'μη', 'μην', 'μἐν', 'μὲν', 'μὴ', 'μὴν', 'να', 'ο', 'οι', 'ομωσ', 'οπωσ', 'οσο', 'οτι', 'οἱ', 'οἳ', 'οἷς', 'οὐ', 'οὐδ', 'οὐδέ', 'οὐδείσ', 'οὐδεὶς', 'οὐδὲ', 'οὐδὲν', 'οὐκ', 'οὐχ', 'οὐχὶ', 'οὓς', 'οὔτε', 'οὕτω', 'οὕτως', 'οὕτωσ', 'οὖν', 'οὗ', 'οὗτος', 'οὗτοσ', 'παρ', 'παρά', 'παρα', 'παρὰ', 'περί', 'περὶ', 'ποια', 'ποιεσ', 'ποιο', 'ποιοι', 'ποιοσ', 'ποιουσ', 'ποιων', 'ποτε', 'που', 'ποῦ', 'προ', 'προσ', 'πρόσ', 'πρὸ', 'πρὸς', 'πως', 'πωσ', 'σε', 'στη', 'στην', 'στο', 'στον', 'σόσ', 'σύ', 'σύν', 'σὸς', 'σὺ', 'σὺν', 'τά', 'τήν', 'τί', 'τίς', 'τίσ', 'τα', 'ταῖς', 'τε', 'την', 'τησ', 'τι', 'τινα', 'τις', 'τισ', 'το', 'τοί', 'τοι', 'τοιοῦτος', 'τοιοῦτοσ', 'τον', 'τοτε', 'του', 'τούσ', 'τοὺς', 'τοῖς', 'τοῦ', 'των', 'τό', 'τόν', 'τότε', 'τὰ', 'τὰς', 'τὴν', 'τὸ', 'τὸν', 'τῆς', 'τῆσ', 'τῇ', 'τῶν', 'τῷ', 'ωσ', \"ἀλλ'\", 'ἀλλά', 'ἀλλὰ', 'ἀλλ’', 'ἀπ', 'ἀπό', 'ἀπὸ', 'ἀφ', 'ἂν', 'ἃ', 'ἄλλος', 'ἄλλοσ', 'ἄν', 'ἄρα', 'ἅμα', 'ἐάν', 'ἐγώ', 'ἐγὼ', 'ἐκ', 'ἐμόσ', 'ἐμὸς', 'ἐν', 'ἐξ', 'ἐπί', 'ἐπεὶ', 'ἐπὶ', 'ἐστι', 'ἐφ', 'ἐὰν', 'ἑαυτοῦ', 'ἔτι', 'ἡ', 'ἢ', 'ἣ', 'ἤ', 'ἥ', 'ἧς', 'ἵνα', 'ὁ', 'ὃ', 'ὃν', 'ὃς', 'ὅ', 'ὅδε', 'ὅθεν', 'ὅπερ', 'ὅς', 'ὅσ', 'ὅστις', 'ὅστισ', 'ὅτε', 'ὅτι', 'ὑμόσ', 'ὑπ', 'ὑπέρ', 'ὑπό', 'ὑπὲρ', 'ὑπὸ', 'ὡς', 'ὡσ', 'ὥς', 'ὥστε', 'ὦ', 'ᾧ']\n"
     ]
    }
   ],
   "source": [
    "# import nltk\n",
    "# stopword_list = nltk.corpus.stopwords.words('greek')\n",
    "# print (stopword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general text preprocessing or wrangling stage.This involves cleaning, preprocessing, and normalizing text to bring text\n",
    "# components like sentences, phrases, and words to some standard format\n",
    "import nltk\n",
    "stopword_list = nltk.corpus.stopwords.words('greek')\n",
    "print (stopword_list)\n",
    "# just to keep negation if any in bi-grams\n",
    "stopword_list.remove('όχι')\n",
    "stopword_list.remove('δεν')\n",
    "\n",
    "# normalize our corpus\n",
    "norm_corpus = tn.normalize_corpus(corpus=data_df['Article'], html_stripping=True, contraction_expansion=True, \n",
    "                                  accented_char_removal=True, text_lower_case=True, text_lemmatization=True, \n",
    "                                  text_stemming=False, special_char_removal=True, remove_digits=True,\n",
    "                                  stopword_removal=True, stopwords=stopword_list)\n",
    "data_df['Clean Article'] = norm_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Clean Article</th>\n",
       "      <th>Target Label</th>\n",
       "      <th>Target Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nI am sure some bashers of Pens fans are pr...</td>\n",
       "      <td>sure basher pens fan pretty confused lack kind...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My brother is in the market for a high-perform...</td>\n",
       "      <td>brother market high performance video card sup...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\n\\n\\tFinally you said what you dream abou...</td>\n",
       "      <td>finally say dream mediterranean new area great...</td>\n",
       "      <td>17</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nThink!\\n\\nIt's the SCSI card doing the DMA t...</td>\n",
       "      <td>think scsi card dma transfer not disk scsi car...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1)    I have an old Jasmine drive which I cann...</td>\n",
       "      <td>old jasmine drive not use new system understan...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n\\nBack in high school I worked as a lab assi...</td>\n",
       "      <td>back high school work lab assistant bunch expe...</td>\n",
       "      <td>12</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n\\nAE is in Dallas...try 214/241-6060 or 214/...</td>\n",
       "      <td>ae dallas try tech support may line one get start</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\n[stuff deleted]\\n\\nOk, here's the solution t...</td>\n",
       "      <td>stuff delete ok solution problem move canada y...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\n\\n\\nYeah, it's the second one.  And I believ...</td>\n",
       "      <td>yeah second one believe price try get good loo...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\nIf a Christian means someone who believes in...</td>\n",
       "      <td>christian mean someone believe divinity jesus ...</td>\n",
       "      <td>19</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  \\\n",
       "0  \\n\\nI am sure some bashers of Pens fans are pr...   \n",
       "1  My brother is in the market for a high-perform...   \n",
       "2  \\n\\n\\n\\n\\tFinally you said what you dream abou...   \n",
       "3  \\nThink!\\n\\nIt's the SCSI card doing the DMA t...   \n",
       "4  1)    I have an old Jasmine drive which I cann...   \n",
       "5  \\n\\nBack in high school I worked as a lab assi...   \n",
       "6  \\n\\nAE is in Dallas...try 214/241-6060 or 214/...   \n",
       "7  \\n[stuff deleted]\\n\\nOk, here's the solution t...   \n",
       "8  \\n\\n\\nYeah, it's the second one.  And I believ...   \n",
       "9  \\nIf a Christian means someone who believes in...   \n",
       "\n",
       "                                       Clean Article  Target Label  \\\n",
       "0  sure basher pens fan pretty confused lack kind...            10   \n",
       "1  brother market high performance video card sup...             3   \n",
       "2  finally say dream mediterranean new area great...            17   \n",
       "3  think scsi card dma transfer not disk scsi car...             3   \n",
       "4  old jasmine drive not use new system understan...             4   \n",
       "5  back high school work lab assistant bunch expe...            12   \n",
       "6  ae dallas try tech support may line one get start             4   \n",
       "7  stuff delete ok solution problem move canada y...            10   \n",
       "8  yeah second one believe price try get good loo...            10   \n",
       "9  christian mean someone believe divinity jesus ...            19   \n",
       "\n",
       "                Target Name  \n",
       "0          rec.sport.hockey  \n",
       "1  comp.sys.ibm.pc.hardware  \n",
       "2     talk.politics.mideast  \n",
       "3  comp.sys.ibm.pc.hardware  \n",
       "4     comp.sys.mac.hardware  \n",
       "5           sci.electronics  \n",
       "6     comp.sys.mac.hardware  \n",
       "7          rec.sport.hockey  \n",
       "8          rec.sport.hockey  \n",
       "9        talk.religion.misc  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view sample data\n",
    "data_df = data_df[['Article', 'Clean Article', 'Target Label', 'Target Name']]\n",
    "data_df.head(10)\n",
    "# The 20 Newsgroups dataset after text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18301 entries, 0 to 18300\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Article        18301 non-null  object\n",
      " 1   Clean Article  18301 non-null  object\n",
      " 2   Target Label   18301 non-null  int64 \n",
      " 3   Target Name    18301 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 714.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data_df = data_df.replace(r'^(\\s?)+$', np.nan, regex=True)\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18301 entries, 0 to 18300\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Article        18301 non-null  object\n",
      " 1   Clean Article  18301 non-null  object\n",
      " 2   Target Label   18301 non-null  int64 \n",
      " 3   Target Name    18301 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 572.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# We definitely have some null articles after our preprocessing operation\n",
    "data_df = data_df.dropna().reset_index(drop=True)\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the dataset using the following code if needed so you don’t need to run the\n",
    "# preprocessing step every time\n",
    "data_df.to_csv('clean_newsgroups.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('clean_newsgroups.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Train and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12261,), (6040,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To build a machine learning system, we need to build our models on training data and\n",
    "# then test and evaluate their performance on test data.\n",
    "# train dataset : test dataset split of 67%/33% of the total data.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_corpus, test_corpus, train_label_nums, test_label_nums, train_label_names, test_label_names =\\\n",
    "                                 train_test_split(np.array(data_df['Clean Article']), np.array(data_df['Target Label']),\n",
    "                                                       np.array(data_df['Target Name']), test_size=0.33, random_state=42)\n",
    "\n",
    "train_corpus.shape, test_corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target Label</th>\n",
       "      <th>Train Count</th>\n",
       "      <th>Test Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>675</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>comp.windows.x</td>\n",
       "      <td>669</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>661</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rec.motorcycles</td>\n",
       "      <td>658</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soc.religion.christian</td>\n",
       "      <td>656</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>655</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sci.electronics</td>\n",
       "      <td>645</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "      <td>642</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sci.med</td>\n",
       "      <td>641</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>641</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>misc.forsale</td>\n",
       "      <td>637</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rec.autos</td>\n",
       "      <td>631</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>631</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "      <td>620</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sci.space</td>\n",
       "      <td>618</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>talk.politics.mideast</td>\n",
       "      <td>596</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>talk.politics.guns</td>\n",
       "      <td>589</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>talk.politics.misc</td>\n",
       "      <td>495</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>489</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>412</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Target Label  Train Count  Test Count\n",
       "6                  sci.crypt          675         287\n",
       "8             comp.windows.x          669         311\n",
       "1              comp.graphics          661         292\n",
       "5            rec.motorcycles          658         311\n",
       "2     soc.religion.christian          656         318\n",
       "0           rec.sport.hockey          655         318\n",
       "14           sci.electronics          645         311\n",
       "15   comp.os.ms-windows.misc          642         304\n",
       "18                   sci.med          641         319\n",
       "7         rec.sport.baseball          641         310\n",
       "11              misc.forsale          637         322\n",
       "12                 rec.autos          631         303\n",
       "4      comp.sys.mac.hardware          631         296\n",
       "17  comp.sys.ibm.pc.hardware          620         343\n",
       "19                 sci.space          618         335\n",
       "13     talk.politics.mideast          596         321\n",
       "9         talk.politics.guns          589         296\n",
       "10        talk.politics.misc          495         260\n",
       "3                alt.atheism          489         290\n",
       "16        talk.religion.misc          412         193"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of train and test articles by the 20 newsgroups\n",
    "from collections import Counter\n",
    "\n",
    "trd = dict(Counter(train_label_names))\n",
    "tsd = dict(Counter(test_label_names))\n",
    "\n",
    "(pd.DataFrame([[key, trd[key], tsd[key]] for key in trd], \n",
    "             columns=['Target Label', 'Train Count', 'Test Count'])\n",
    ".sort_values(by=['Train Count', 'Test Count'],\n",
    "             ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering Techniques\n",
    "In machine learning terminology, features are unique measurable attributes or\n",
    "properties for each observation or data point in a dataset. Features are usually numeric in nature and can be absolute numeric values or categorical features that can be encoded as binary features for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words Features with Classification Models\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# build BOW features on train articles\n",
    "cv = CountVectorizer(binary=False, min_df=0.0, max_df=1.0)\n",
    "cv_train_features = cv.fit_transform(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform test articles into features\n",
    "cv_test_features = cv.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW model:> Train features shape: (12261, 74354)  Test features shape: (6040, 74354)\n"
     ]
    }
   ],
   "source": [
    "print('BOW model:> Train features shape:', cv_train_features.shape, ' Test features shape:', cv_test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models (with sklearn...)\n",
    "Build several classifiers on these features using the training data and test\n",
    "their performance on the test dataset and then check model accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.67713004 0.64600326 0.67495922 0.67128874 0.66598695]\n",
      "Mean CV Accuracy: 0.6670736435526229\n",
      "Test Accuracy: 0.6811258278145695\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB(alpha=1)\n",
    "mnb.fit(cv_train_features, train_label_names)\n",
    "mnb_bow_cv_scores = cross_val_score(mnb, cv_train_features, train_label_names, cv=5)\n",
    "mnb_bow_cv_mean_score = np.mean(mnb_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', mnb_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', mnb_bow_cv_mean_score)\n",
    "mnb_bow_test_score = mnb.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', mnb_bow_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.68202201 0.67128874 0.68515498 0.68760196 0.66965742]\n",
      "Mean CV Accuracy: 0.6791450226742366\n",
      "Test Accuracy: 0.6910596026490067\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', max_iter=100, C=1, random_state=42)\n",
    "lr.fit(cv_train_features, train_label_names)\n",
    "lr_bow_cv_scores = cross_val_score(lr, cv_train_features, train_label_names, cv=5)\n",
    "lr_bow_cv_mean_score = np.mean(lr_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', lr_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', lr_bow_cv_mean_score)\n",
    "lr_bow_test_score = lr.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', lr_bow_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.63065634 0.637031   0.65375204 0.6411093  0.637031  ]\n",
      "Mean CV Accuracy: 0.6399159334144228\n",
      "Test Accuracy: 0.6582781456953642\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm = LinearSVC(penalty='l2', C=1, random_state=42)\n",
    "svm.fit(cv_train_features, train_label_names)\n",
    "svm_bow_cv_scores = cross_val_score(svm, cv_train_features, train_label_names, cv=5)\n",
    "svm_bow_cv_mean_score = np.mean(svm_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', svm_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', svm_bow_cv_mean_score)\n",
    "svm_bow_test_score = svm.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', svm_bow_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM with Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.64492458 0.63907015 0.63295269 0.64355628 0.6451876 ]\n",
      "Mean CV Accuracy: 0.6411382606376718\n",
      "Test Accuracy: 0.653476821192053\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "svm_sgd = SGDClassifier(loss='hinge', penalty='l2', max_iter=5, random_state=42)\n",
    "svm_sgd.fit(cv_train_features, train_label_names)\n",
    "svmsgd_bow_cv_scores = cross_val_score(svm_sgd, cv_train_features, train_label_names, cv=5)\n",
    "svmsgd_bow_cv_mean_score = np.mean(svmsgd_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', svmsgd_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', svmsgd_bow_cv_mean_score)\n",
    "svmsgd_bow_test_score = svm_sgd.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', svmsgd_bow_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.5108031  0.51957586 0.5175367  0.52895595 0.52528548]\n",
      "Mean CV Accuracy: 0.5204314189968803\n",
      "Test Accuracy: 0.5347682119205298\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "rfc.fit(cv_train_features, train_label_names)\n",
    "rfc_bow_cv_scores = cross_val_score(rfc, cv_train_features, train_label_names, cv=5)\n",
    "rfc_bow_cv_mean_score = np.mean(rfc_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', rfc_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', rfc_bow_cv_mean_score)\n",
    "rfc_bow_test_score = rfc.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', rfc_bow_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.54830819 0.52732463 0.55628059 0.5632137  0.55872757]\n",
      "Mean CV Accuracy: 0.5507709373414317\n",
      "Test Accuracy: 0.5529801324503312\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=10, random_state=42)\n",
    "gbc.fit(cv_train_features, train_label_names)\n",
    "gbc_bow_cv_scores = cross_val_score(gbc, cv_train_features, train_label_names, cv=5)\n",
    "gbc_bow_cv_mean_score = np.mean(gbc_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', gbc_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', gbc_bow_cv_mean_score)\n",
    "gbc_bow_test_score = gbc.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', gbc_bow_test_score)\n",
    "\n",
    "# It is interesting to see that simpler models like Naοve Bayes and Logistic Regression\n",
    "# performed much better than the ensemble models!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Features with Classification Models\n",
    "We use TF-IDF features to train our classification models. Assuming TF-IDF weighs down unimportant features, we might get better performing models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# build BOW features on train articles\n",
    "tv = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0)\n",
    "tv_train_features = tv.fit_transform(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform test articles into features\n",
    "tv_test_features = tv.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF model:> Train features shape: (12261, 74354)  Test features shape: (6040, 74354)\n"
     ]
    }
   ],
   "source": [
    "print('TFIDF model:> Train features shape:', tv_train_features.shape, ' Test features shape:', tv_test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now build several classifiers on these features using the training data and test their performance on the test dataset using all the classification models. We also check model accuracies using five-fold cross validation, just like we did earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.71300448 0.68760196 0.7137031  0.71411093 0.71044046]\n",
      "Mean CV Accuracy: 0.7077721856048691\n",
      "Test Accuracy: 0.7115894039735099\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=1)\n",
    "mnb.fit(tv_train_features, train_label_names)\n",
    "mnb_tfidf_cv_scores = cross_val_score(mnb, tv_train_features, train_label_names, cv=5)\n",
    "mnb_tfidf_cv_mean_score = np.mean(mnb_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', mnb_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', mnb_tfidf_cv_mean_score)\n",
    "mnb_tfidf_test_score = mnb.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', mnb_tfidf_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "(time inefficiency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.74276396 0.71818923 0.75040783 0.74551387 0.73694943]\n",
      "Mean CV Accuracy: 0.7387648642771211\n",
      "Test Accuracy: 0.7506622516556292\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2', max_iter=100, C=1, random_state=42)\n",
    "lr.fit(tv_train_features, train_label_names)\n",
    "lr_tfidf_cv_scores = cross_val_score(lr, tv_train_features, train_label_names, cv=5)\n",
    "lr_tfidf_cv_mean_score = np.mean(lr_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', lr_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', lr_tfidf_cv_mean_score)\n",
    "lr_tfidf_test_score = lr.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', lr_tfidf_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.75540155 0.73898858 0.7593801  0.76835237 0.75163132]\n",
      "Mean CV Accuracy: 0.7547507829079019\n",
      "Test Accuracy: 0.7695364238410596\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC(penalty='l2', C=1, random_state=42)\n",
    "svm.fit(tv_train_features, train_label_names)\n",
    "svm_tfidf_cv_scores = cross_val_score(svm, tv_train_features, train_label_names, cv=5)\n",
    "svm_tfidf_cv_mean_score = np.mean(svm_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', svm_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', svm_tfidf_cv_mean_score)\n",
    "svm_tfidf_test_score = svm.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', svm_tfidf_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM with Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.75662454 0.73735726 0.76101142 0.77324633 0.75652529]\n",
      "Mean CV Accuracy: 0.7569529670031503\n",
      "Test Accuracy: 0.7675496688741722\n"
     ]
    }
   ],
   "source": [
    "svm_sgd = SGDClassifier(loss='hinge', penalty='l2', max_iter=5, random_state=42)\n",
    "svm_sgd.fit(tv_train_features, train_label_names)\n",
    "svmsgd_tfidf_cv_scores = cross_val_score(svm_sgd, tv_train_features, train_label_names, cv=5)\n",
    "svmsgd_tfidf_cv_mean_score = np.mean(svmsgd_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', svmsgd_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', svmsgd_tfidf_cv_mean_score)\n",
    "svmsgd_tfidf_test_score = svm_sgd.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', svmsgd_tfidf_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.52588667 0.51631321 0.52079935 0.52814029 0.52446982]\n",
      "Mean CV Accuracy: 0.5231218689502949\n",
      "Test Accuracy: 0.5413907284768212\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "rfc.fit(tv_train_features, train_label_names)\n",
    "rfc_tfidf_cv_scores = cross_val_score(rfc, tv_train_features, train_label_names, cv=5)\n",
    "rfc_tfidf_cv_mean_score = np.mean(rfc_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', rfc_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', rfc_tfidf_cv_mean_score)\n",
    "rfc_tfidf_test_score = rfc.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', rfc_tfidf_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.54830819 0.53181077 0.56158238 0.57911909 0.55668842]\n",
      "Mean CV Accuracy: 0.5555017693153305\n",
      "Test Accuracy: 0.5556291390728477\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators=10, random_state=42)\n",
    "gbc.fit(tv_train_features, train_label_names)\n",
    "gbc_tfidf_cv_scores = cross_val_score(gbc, tv_train_features, train_label_names, cv=5)\n",
    "gbc_tfidf_cv_mean_score = np.mean(gbc_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', gbc_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', gbc_tfidf_cv_mean_score)\n",
    "gbc_tfidf_test_score = gbc.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', gbc_tfidf_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It’s interesting to see that the overall accuracy of several models (with TF-IDF) increases by quite a bit, including logistic regression, Naïve Bayes, and SVM. Interestingly, the ensemble models don’t perform as well. Using more estimators might improve them, but still wouldn’t be as good as the other models and it would take a huge amount of training time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparative Model Performance Evaluation\n",
    "We can now do a nice comparison of all the models we have tried so far with the two different feature engineering techniques. We will build a dataframe from our modeling results and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>Linear SVM (SGD)</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Gradient Boosted Machines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV Score (TF)</th>\n",
       "      <td>0.667074</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.639916</td>\n",
       "      <td>0.641138</td>\n",
       "      <td>0.520431</td>\n",
       "      <td>0.550771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Score (TF)</th>\n",
       "      <td>0.681126</td>\n",
       "      <td>0.69106</td>\n",
       "      <td>0.658278</td>\n",
       "      <td>0.653477</td>\n",
       "      <td>0.534768</td>\n",
       "      <td>0.55298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV Score (TF-IDF)</th>\n",
       "      <td>0.707772</td>\n",
       "      <td>0.738765</td>\n",
       "      <td>0.754751</td>\n",
       "      <td>0.756953</td>\n",
       "      <td>0.523122</td>\n",
       "      <td>0.555502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Score (TF-IDF)</th>\n",
       "      <td>0.711589</td>\n",
       "      <td>0.750662</td>\n",
       "      <td>0.769536</td>\n",
       "      <td>0.76755</td>\n",
       "      <td>0.541391</td>\n",
       "      <td>0.555629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0                    1           2  \\\n",
       "Model                Naive Bayes  Logistic Regression  Linear SVM   \n",
       "CV Score (TF)           0.667074             0.679145    0.639916   \n",
       "Test Score (TF)         0.681126              0.69106    0.658278   \n",
       "CV Score (TF-IDF)       0.707772             0.738765    0.754751   \n",
       "Test Score (TF-IDF)     0.711589             0.750662    0.769536   \n",
       "\n",
       "                                    3              4  \\\n",
       "Model                Linear SVM (SGD)  Random Forest   \n",
       "CV Score (TF)                0.641138       0.520431   \n",
       "Test Score (TF)              0.653477       0.534768   \n",
       "CV Score (TF-IDF)            0.756953       0.523122   \n",
       "Test Score (TF-IDF)           0.76755       0.541391   \n",
       "\n",
       "                                             5  \n",
       "Model                Gradient Boosted Machines  \n",
       "CV Score (TF)                         0.550771  \n",
       "Test Score (TF)                        0.55298  \n",
       "CV Score (TF-IDF)                     0.555502  \n",
       "Test Score (TF-IDF)                   0.555629  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([['Naive Bayes', mnb_bow_cv_mean_score, mnb_bow_test_score, \n",
    "               mnb_tfidf_cv_mean_score, mnb_tfidf_test_score],\n",
    "              ['Logistic Regression', lr_bow_cv_mean_score, lr_bow_test_score, \n",
    "               lr_tfidf_cv_mean_score, lr_tfidf_test_score],\n",
    "              ['Linear SVM', svm_bow_cv_mean_score, svm_bow_test_score, \n",
    "               svm_tfidf_cv_mean_score, svm_tfidf_test_score],\n",
    "              ['Linear SVM (SGD)', svmsgd_bow_cv_mean_score, svmsgd_bow_test_score, \n",
    "               svmsgd_tfidf_cv_mean_score, svmsgd_tfidf_test_score],\n",
    "              ['Random Forest', rfc_bow_cv_mean_score, rfc_bow_test_score, \n",
    "               rfc_tfidf_cv_mean_score, rfc_tfidf_test_score],\n",
    "              ['Gradient Boosted Machines', gbc_bow_cv_mean_score, gbc_bow_test_score, \n",
    "               gbc_tfidf_cv_mean_score, gbc_tfidf_test_score]],\n",
    "             columns=['Model', 'CV Score (TF)', 'Test Score (TF)', 'CV Score (TF-IDF)', 'Test Score (TF-IDF)'],\n",
    "             ).T\n",
    "\n",
    "# Comparative model performance evaluation\n",
    "# the best performing models were SVM followed by Logistic Regression and Naïve Bayes. \n",
    "# Ensemble models didn’t perform as well on this # dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning our Multinomial Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] mnb__alpha=1e-05, tfidf__ngram_range=(1, 1) .....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... mnb__alpha=1e-05, tfidf__ngram_range=(1, 1), total=   2.2s\n",
      "[CV] mnb__alpha=1e-05, tfidf__ngram_range=(1, 1) .....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... mnb__alpha=1e-05, tfidf__ngram_range=(1, 1), total=   1.7s\n",
      "[CV] mnb__alpha=1e-05, tfidf__ngram_range=(1, 1) .....................\n",
      "[CV] ...... mnb__alpha=1e-05, tfidf__ngram_range=(1, 1), total=   1.7s\n",
      "[CV] mnb__alpha=1e-05, tfidf__ngram_range=(1, 1) .....................\n",
      "[CV] ...... mnb__alpha=1e-05, tfidf__ngram_range=(1, 1), total=   1.7s\n",
      "[CV] mnb__alpha=1e-05, tfidf__ngram_range=(1, 1) .....................\n",
      "[CV] ...... mnb__alpha=1e-05, tfidf__ngram_range=(1, 1), total=   1.7s\n",
      "[CV] mnb__alpha=1e-05, tfidf__ngram_range=(1, 2) .....................\n",
      "[CV] ...... mnb__alpha=1e-05, tfidf__ngram_range=(1, 2), total=   7.4s\n",
      "[CV] mnb__alpha=1e-05, tfidf__ngram_range=(1, 2) .....................\n",
      "[CV] ...... mnb__alpha=1e-05, tfidf__ngram_range=(1, 2), total=   7.1s\n",
      "[CV] mnb__alpha=1e-05, tfidf__ngram_range=(1, 2) .....................\n",
      "[CV] ...... mnb__alpha=1e-05, tfidf__ngram_range=(1, 2), total=   8.0s\n",
      "[CV] mnb__alpha=1e-05, tfidf__ngram_range=(1, 2) .....................\n",
      "[CV] ...... mnb__alpha=1e-05, tfidf__ngram_range=(1, 2), total=   7.6s\n",
      "[CV] mnb__alpha=1e-05, tfidf__ngram_range=(1, 2) .....................\n",
      "[CV] ...... mnb__alpha=1e-05, tfidf__ngram_range=(1, 2), total=   7.8s\n",
      "[CV] mnb__alpha=0.0001, tfidf__ngram_range=(1, 1) ....................\n",
      "[CV] ..... mnb__alpha=0.0001, tfidf__ngram_range=(1, 1), total=   1.7s\n",
      "[CV] mnb__alpha=0.0001, tfidf__ngram_range=(1, 1) ....................\n",
      "[CV] ..... mnb__alpha=0.0001, tfidf__ngram_range=(1, 1), total=   2.1s\n",
      "[CV] mnb__alpha=0.0001, tfidf__ngram_range=(1, 1) ....................\n",
      "[CV] ..... mnb__alpha=0.0001, tfidf__ngram_range=(1, 1), total=   2.3s\n",
      "[CV] mnb__alpha=0.0001, tfidf__ngram_range=(1, 1) ....................\n",
      "[CV] ..... mnb__alpha=0.0001, tfidf__ngram_range=(1, 1), total=   2.8s\n",
      "[CV] mnb__alpha=0.0001, tfidf__ngram_range=(1, 1) ....................\n",
      "[CV] ..... mnb__alpha=0.0001, tfidf__ngram_range=(1, 1), total=   1.9s\n",
      "[CV] mnb__alpha=0.0001, tfidf__ngram_range=(1, 2) ....................\n",
      "[CV] ..... mnb__alpha=0.0001, tfidf__ngram_range=(1, 2), total=  11.9s\n",
      "[CV] mnb__alpha=0.0001, tfidf__ngram_range=(1, 2) ....................\n",
      "[CV] ..... mnb__alpha=0.0001, tfidf__ngram_range=(1, 2), total=  11.3s\n",
      "[CV] mnb__alpha=0.0001, tfidf__ngram_range=(1, 2) ....................\n",
      "[CV] ..... mnb__alpha=0.0001, tfidf__ngram_range=(1, 2), total=  12.8s\n",
      "[CV] mnb__alpha=0.0001, tfidf__ngram_range=(1, 2) ....................\n",
      "[CV] ..... mnb__alpha=0.0001, tfidf__ngram_range=(1, 2), total=   9.7s\n",
      "[CV] mnb__alpha=0.0001, tfidf__ngram_range=(1, 2) ....................\n",
      "[CV] ..... mnb__alpha=0.0001, tfidf__ngram_range=(1, 2), total=   7.3s\n",
      "[CV] mnb__alpha=0.01, tfidf__ngram_range=(1, 1) ......................\n",
      "[CV] ....... mnb__alpha=0.01, tfidf__ngram_range=(1, 1), total=   1.9s\n",
      "[CV] mnb__alpha=0.01, tfidf__ngram_range=(1, 1) ......................\n",
      "[CV] ....... mnb__alpha=0.01, tfidf__ngram_range=(1, 1), total=   1.8s\n",
      "[CV] mnb__alpha=0.01, tfidf__ngram_range=(1, 1) ......................\n",
      "[CV] ....... mnb__alpha=0.01, tfidf__ngram_range=(1, 1), total=   1.7s\n",
      "[CV] mnb__alpha=0.01, tfidf__ngram_range=(1, 1) ......................\n",
      "[CV] ....... mnb__alpha=0.01, tfidf__ngram_range=(1, 1), total=   1.7s\n",
      "[CV] mnb__alpha=0.01, tfidf__ngram_range=(1, 1) ......................\n",
      "[CV] ....... mnb__alpha=0.01, tfidf__ngram_range=(1, 1), total=   1.7s\n",
      "[CV] mnb__alpha=0.01, tfidf__ngram_range=(1, 2) ......................\n",
      "[CV] ....... mnb__alpha=0.01, tfidf__ngram_range=(1, 2), total=   7.4s\n",
      "[CV] mnb__alpha=0.01, tfidf__ngram_range=(1, 2) ......................\n",
      "[CV] ....... mnb__alpha=0.01, tfidf__ngram_range=(1, 2), total=   7.7s\n",
      "[CV] mnb__alpha=0.01, tfidf__ngram_range=(1, 2) ......................\n",
      "[CV] ....... mnb__alpha=0.01, tfidf__ngram_range=(1, 2), total=   7.4s\n",
      "[CV] mnb__alpha=0.01, tfidf__ngram_range=(1, 2) ......................\n",
      "[CV] ....... mnb__alpha=0.01, tfidf__ngram_range=(1, 2), total=   7.6s\n",
      "[CV] mnb__alpha=0.01, tfidf__ngram_range=(1, 2) ......................\n",
      "[CV] ....... mnb__alpha=0.01, tfidf__ngram_range=(1, 2), total=   7.6s\n",
      "[CV] mnb__alpha=0.1, tfidf__ngram_range=(1, 1) .......................\n",
      "[CV] ........ mnb__alpha=0.1, tfidf__ngram_range=(1, 1), total=   1.7s\n",
      "[CV] mnb__alpha=0.1, tfidf__ngram_range=(1, 1) .......................\n",
      "[CV] ........ mnb__alpha=0.1, tfidf__ngram_range=(1, 1), total=   1.8s\n",
      "[CV] mnb__alpha=0.1, tfidf__ngram_range=(1, 1) .......................\n",
      "[CV] ........ mnb__alpha=0.1, tfidf__ngram_range=(1, 1), total=   1.8s\n",
      "[CV] mnb__alpha=0.1, tfidf__ngram_range=(1, 1) .......................\n",
      "[CV] ........ mnb__alpha=0.1, tfidf__ngram_range=(1, 1), total=   1.9s\n",
      "[CV] mnb__alpha=0.1, tfidf__ngram_range=(1, 1) .......................\n",
      "[CV] ........ mnb__alpha=0.1, tfidf__ngram_range=(1, 1), total=   1.7s\n",
      "[CV] mnb__alpha=0.1, tfidf__ngram_range=(1, 2) .......................\n",
      "[CV] ........ mnb__alpha=0.1, tfidf__ngram_range=(1, 2), total=   7.4s\n",
      "[CV] mnb__alpha=0.1, tfidf__ngram_range=(1, 2) .......................\n",
      "[CV] ........ mnb__alpha=0.1, tfidf__ngram_range=(1, 2), total=   7.6s\n",
      "[CV] mnb__alpha=0.1, tfidf__ngram_range=(1, 2) .......................\n",
      "[CV] ........ mnb__alpha=0.1, tfidf__ngram_range=(1, 2), total=   7.3s\n",
      "[CV] mnb__alpha=0.1, tfidf__ngram_range=(1, 2) .......................\n",
      "[CV] ........ mnb__alpha=0.1, tfidf__ngram_range=(1, 2), total=   7.6s\n",
      "[CV] mnb__alpha=0.1, tfidf__ngram_range=(1, 2) .......................\n",
      "[CV] ........ mnb__alpha=0.1, tfidf__ngram_range=(1, 2), total=   7.4s\n",
      "[CV] mnb__alpha=1, tfidf__ngram_range=(1, 1) .........................\n",
      "[CV] .......... mnb__alpha=1, tfidf__ngram_range=(1, 1), total=   1.7s\n",
      "[CV] mnb__alpha=1, tfidf__ngram_range=(1, 1) .........................\n",
      "[CV] .......... mnb__alpha=1, tfidf__ngram_range=(1, 1), total=   1.7s\n",
      "[CV] mnb__alpha=1, tfidf__ngram_range=(1, 1) .........................\n",
      "[CV] .......... mnb__alpha=1, tfidf__ngram_range=(1, 1), total=   1.7s\n",
      "[CV] mnb__alpha=1, tfidf__ngram_range=(1, 1) .........................\n",
      "[CV] .......... mnb__alpha=1, tfidf__ngram_range=(1, 1), total=   1.7s\n",
      "[CV] mnb__alpha=1, tfidf__ngram_range=(1, 1) .........................\n",
      "[CV] .......... mnb__alpha=1, tfidf__ngram_range=(1, 1), total=   1.7s\n",
      "[CV] mnb__alpha=1, tfidf__ngram_range=(1, 2) .........................\n",
      "[CV] .......... mnb__alpha=1, tfidf__ngram_range=(1, 2), total=   7.2s\n",
      "[CV] mnb__alpha=1, tfidf__ngram_range=(1, 2) .........................\n",
      "[CV] .......... mnb__alpha=1, tfidf__ngram_range=(1, 2), total=   7.1s\n",
      "[CV] mnb__alpha=1, tfidf__ngram_range=(1, 2) .........................\n",
      "[CV] .......... mnb__alpha=1, tfidf__ngram_range=(1, 2), total=   7.1s\n",
      "[CV] mnb__alpha=1, tfidf__ngram_range=(1, 2) .........................\n",
      "[CV] .......... mnb__alpha=1, tfidf__ngram_range=(1, 2), total=   7.1s\n",
      "[CV] mnb__alpha=1, tfidf__ngram_range=(1, 2) .........................\n",
      "[CV] .......... mnb__alpha=1, tfidf__ngram_range=(1, 2), total=   7.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  4.2min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "mnb_pipeline = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                        ('mnb', MultinomialNB())\n",
    "                       ])\n",
    "\n",
    "param_grid = {'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "              'mnb__alpha': [1e-5, 1e-4, 1e-2, 1e-1, 1]\n",
    "}\n",
    "\n",
    "gs_mnb = GridSearchCV(mnb_pipeline, param_grid, cv=5, verbose=2)\n",
    "gs_mnb = gs_mnb.fit(train_corpus, train_label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('tfidf',\n",
       "   TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                   dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                   input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                   min_df=1, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
       "                   smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                   sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                   tokenizer=None, use_idf=True, vocabulary=None)),\n",
       "  ('mnb', MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True))],\n",
       " 'verbose': False,\n",
       " 'tfidf': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                 dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                 input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                 min_df=1, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
       "                 smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                 sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                 tokenizer=None, use_idf=True, vocabulary=None),\n",
       " 'mnb': MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True),\n",
       " 'tfidf__analyzer': 'word',\n",
       " 'tfidf__binary': False,\n",
       " 'tfidf__decode_error': 'strict',\n",
       " 'tfidf__dtype': numpy.float64,\n",
       " 'tfidf__encoding': 'utf-8',\n",
       " 'tfidf__input': 'content',\n",
       " 'tfidf__lowercase': True,\n",
       " 'tfidf__max_df': 1.0,\n",
       " 'tfidf__max_features': None,\n",
       " 'tfidf__min_df': 1,\n",
       " 'tfidf__ngram_range': (1, 2),\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__preprocessor': None,\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__stop_words': None,\n",
       " 'tfidf__strip_accents': None,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tfidf__tokenizer': None,\n",
       " 'tfidf__use_idf': True,\n",
       " 'tfidf__vocabulary': None,\n",
       " 'mnb__alpha': 0.01,\n",
       " 'mnb__class_prior': None,\n",
       " 'mnb__fit_prior': True}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now inspect the hyperparameter values chosen for our best estimator/model\n",
    "# using the following code.\n",
    "gs_mnb.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>params</th>\n",
       "      <th>cv score (mean)</th>\n",
       "      <th>cv score (std)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>{'mnb__alpha': 0.01, 'tfidf__ngram_range': (1, 2)}</td>\n",
       "      <td>0.767066</td>\n",
       "      <td>0.007905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>{'mnb__alpha': 0.01, 'tfidf__ngram_range': (1, 1)}</td>\n",
       "      <td>0.765271</td>\n",
       "      <td>0.009751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>{'mnb__alpha': 0.1, 'tfidf__ngram_range': (1, 2)}</td>\n",
       "      <td>0.753853</td>\n",
       "      <td>0.010498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>{'mnb__alpha': 0.1, 'tfidf__ngram_range': (1, 1)}</td>\n",
       "      <td>0.753608</td>\n",
       "      <td>0.011194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>{'mnb__alpha': 0.0001, 'tfidf__ngram_range': (1, 2)}</td>\n",
       "      <td>0.751978</td>\n",
       "      <td>0.008194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>{'mnb__alpha': 1e-05, 'tfidf__ngram_range': (1, 2)}</td>\n",
       "      <td>0.743414</td>\n",
       "      <td>0.007090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>{'mnb__alpha': 0.0001, 'tfidf__ngram_range': (1, 1)}</td>\n",
       "      <td>0.738194</td>\n",
       "      <td>0.011726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>{'mnb__alpha': 1e-05, 'tfidf__ngram_range': (1, 1)}</td>\n",
       "      <td>0.727183</td>\n",
       "      <td>0.013060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>{'mnb__alpha': 1, 'tfidf__ngram_range': (1, 1)}</td>\n",
       "      <td>0.710219</td>\n",
       "      <td>0.010015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>{'mnb__alpha': 1, 'tfidf__ngram_range': (1, 2)}</td>\n",
       "      <td>0.702390</td>\n",
       "      <td>0.009959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank                                                params  \\\n",
       "5     1    {'mnb__alpha': 0.01, 'tfidf__ngram_range': (1, 2)}   \n",
       "4     2    {'mnb__alpha': 0.01, 'tfidf__ngram_range': (1, 1)}   \n",
       "7     3     {'mnb__alpha': 0.1, 'tfidf__ngram_range': (1, 2)}   \n",
       "6     4     {'mnb__alpha': 0.1, 'tfidf__ngram_range': (1, 1)}   \n",
       "3     5  {'mnb__alpha': 0.0001, 'tfidf__ngram_range': (1, 2)}   \n",
       "1     6   {'mnb__alpha': 1e-05, 'tfidf__ngram_range': (1, 2)}   \n",
       "2     7  {'mnb__alpha': 0.0001, 'tfidf__ngram_range': (1, 1)}   \n",
       "0     8   {'mnb__alpha': 1e-05, 'tfidf__ngram_range': (1, 1)}   \n",
       "8     9       {'mnb__alpha': 1, 'tfidf__ngram_range': (1, 1)}   \n",
       "9    10       {'mnb__alpha': 1, 'tfidf__ngram_range': (1, 2)}   \n",
       "\n",
       "   cv score (mean)  cv score (std)  \n",
       "5         0.767066        0.007905  \n",
       "4         0.765271        0.009751  \n",
       "7         0.753853        0.010498  \n",
       "6         0.753608        0.011194  \n",
       "3         0.751978        0.008194  \n",
       "1         0.743414        0.007090  \n",
       "2         0.738194        0.011726  \n",
       "0         0.727183        0.013060  \n",
       "8         0.710219        0.010015  \n",
       "9         0.702390        0.009959  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now you might be wondering how these hyperparameters specifically were selected\n",
    "# for the best estimator. Well, it decided this based on the model performance, with those\n",
    "# hyperparameter values on the five-folds of validation data during cross-validation.\n",
    "cv_results = gs_mnb.cv_results_\n",
    "results_df = pd.DataFrame({'rank': cv_results['rank_test_score'],\n",
    "                           'params': cv_results['params'], \n",
    "                           'cv score (mean)': cv_results['mean_test_score'], \n",
    "                           'cv score (std)': cv_results['std_test_score']} \n",
    "              )\n",
    "results_df = results_df.sort_values(by=['rank'], ascending=True)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "results_df\n",
    "\n",
    "# Model performances across different hyperparameter values in the\n",
    "# hyperparameter space\n",
    "\n",
    "# you can see how the best hyperparameters including bi-gram TF-IDF features gave the best cross-validation accuracy.\n",
    "# Note that we are never tuning our models based on test data scores, because that would end up biasing our\n",
    "# model toward the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.7791390728476821\n"
     ]
    }
   ],
   "source": [
    "# check our tuned model’s performance on the test data.\n",
    "best_mnb_test_score = gs_mnb.score(test_corpus, test_label_names)\n",
    "print('Test Accuracy :', best_mnb_test_score)\n",
    "# Looks like we have achieved a model accuracy of 77.3%, which is an improvement of\n",
    "# 6% over the base model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning our Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let’s look at how it performs for logistic regression now.\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] lr__C=1, tfidf__ngram_range=(1, 1) ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... lr__C=1, tfidf__ngram_range=(1, 1), total=  36.3s\n",
      "[CV] lr__C=1, tfidf__ngram_range=(1, 1) ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   36.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... lr__C=1, tfidf__ngram_range=(1, 1), total=  34.8s\n",
      "[CV] lr__C=1, tfidf__ngram_range=(1, 1) ..............................\n",
      "[CV] ............... lr__C=1, tfidf__ngram_range=(1, 1), total=  36.6s\n",
      "[CV] lr__C=1, tfidf__ngram_range=(1, 1) ..............................\n",
      "[CV] ............... lr__C=1, tfidf__ngram_range=(1, 1), total=  35.9s\n",
      "[CV] lr__C=1, tfidf__ngram_range=(1, 1) ..............................\n",
      "[CV] ............... lr__C=1, tfidf__ngram_range=(1, 1), total=  33.7s\n",
      "[CV] lr__C=1, tfidf__ngram_range=(1, 2) ..............................\n",
      "[CV] ............... lr__C=1, tfidf__ngram_range=(1, 2), total= 4.8min\n",
      "[CV] lr__C=1, tfidf__ngram_range=(1, 2) ..............................\n",
      "[CV] ............... lr__C=1, tfidf__ngram_range=(1, 2), total= 4.3min\n",
      "[CV] lr__C=1, tfidf__ngram_range=(1, 2) ..............................\n",
      "[CV] ............... lr__C=1, tfidf__ngram_range=(1, 2), total= 3.6min\n",
      "[CV] lr__C=1, tfidf__ngram_range=(1, 2) ..............................\n",
      "[CV] ............... lr__C=1, tfidf__ngram_range=(1, 2), total= 3.7min\n",
      "[CV] lr__C=1, tfidf__ngram_range=(1, 2) ..............................\n",
      "[CV] ............... lr__C=1, tfidf__ngram_range=(1, 2), total= 5.0min\n",
      "[CV] lr__C=5, tfidf__ngram_range=(1, 1) ..............................\n",
      "[CV] ............... lr__C=5, tfidf__ngram_range=(1, 1), total=  38.6s\n",
      "[CV] lr__C=5, tfidf__ngram_range=(1, 1) ..............................\n",
      "[CV] ............... lr__C=5, tfidf__ngram_range=(1, 1), total=  38.7s\n",
      "[CV] lr__C=5, tfidf__ngram_range=(1, 1) ..............................\n",
      "[CV] ............... lr__C=5, tfidf__ngram_range=(1, 1), total=  40.8s\n",
      "[CV] lr__C=5, tfidf__ngram_range=(1, 1) ..............................\n",
      "[CV] ............... lr__C=5, tfidf__ngram_range=(1, 1), total=  38.9s\n",
      "[CV] lr__C=5, tfidf__ngram_range=(1, 1) ..............................\n",
      "[CV] ............... lr__C=5, tfidf__ngram_range=(1, 1), total=  39.9s\n",
      "[CV] lr__C=5, tfidf__ngram_range=(1, 2) ..............................\n",
      "[CV] ............... lr__C=5, tfidf__ngram_range=(1, 2), total= 6.3min\n",
      "[CV] lr__C=5, tfidf__ngram_range=(1, 2) ..............................\n",
      "[CV] ............... lr__C=5, tfidf__ngram_range=(1, 2), total= 6.1min\n",
      "[CV] lr__C=5, tfidf__ngram_range=(1, 2) ..............................\n",
      "[CV] ............... lr__C=5, tfidf__ngram_range=(1, 2), total= 6.4min\n",
      "[CV] lr__C=5, tfidf__ngram_range=(1, 2) ..............................\n",
      "[CV] ............... lr__C=5, tfidf__ngram_range=(1, 2), total= 6.1min\n",
      "[CV] lr__C=5, tfidf__ngram_range=(1, 2) ..............................\n",
      "[CV] ............... lr__C=5, tfidf__ngram_range=(1, 2), total= 7.3min\n",
      "[CV] lr__C=10, tfidf__ngram_range=(1, 1) .............................\n",
      "[CV] .............. lr__C=10, tfidf__ngram_range=(1, 1), total=  39.0s\n",
      "[CV] lr__C=10, tfidf__ngram_range=(1, 1) .............................\n",
      "[CV] .............. lr__C=10, tfidf__ngram_range=(1, 1), total=  38.3s\n",
      "[CV] lr__C=10, tfidf__ngram_range=(1, 1) .............................\n",
      "[CV] .............. lr__C=10, tfidf__ngram_range=(1, 1), total=  41.4s\n",
      "[CV] lr__C=10, tfidf__ngram_range=(1, 1) .............................\n",
      "[CV] .............. lr__C=10, tfidf__ngram_range=(1, 1), total=  40.5s\n",
      "[CV] lr__C=10, tfidf__ngram_range=(1, 1) .............................\n",
      "[CV] .............. lr__C=10, tfidf__ngram_range=(1, 1), total=  39.1s\n",
      "[CV] lr__C=10, tfidf__ngram_range=(1, 2) .............................\n",
      "[CV] .............. lr__C=10, tfidf__ngram_range=(1, 2), total= 6.0min\n",
      "[CV] lr__C=10, tfidf__ngram_range=(1, 2) .............................\n",
      "[CV] .............. lr__C=10, tfidf__ngram_range=(1, 2), total= 5.5min\n",
      "[CV] lr__C=10, tfidf__ngram_range=(1, 2) .............................\n",
      "[CV] .............. lr__C=10, tfidf__ngram_range=(1, 2), total= 6.5min\n",
      "[CV] lr__C=10, tfidf__ngram_range=(1, 2) .............................\n",
      "[CV] .............. lr__C=10, tfidf__ngram_range=(1, 2), total= 6.3min\n",
      "[CV] lr__C=10, tfidf__ngram_range=(1, 2) .............................\n",
      "[CV] .............. lr__C=10, tfidf__ngram_range=(1, 2), total= 6.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 94.2min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lr_pipeline = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                        ('lr', LogisticRegression(penalty='l2', max_iter=100, random_state=42))\n",
    "                       ])\n",
    "\n",
    "param_grid = {'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "              'lr__C': [1, 5, 10]\n",
    "}\n",
    "\n",
    "gs_lr = GridSearchCV(lr_pipeline, param_grid, cv=5, verbose=2)\n",
    "gs_lr = gs_lr.fit(train_corpus, train_label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       " ...alty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.766926005628\n"
     ]
    }
   ],
   "source": [
    "best_lr_test_score = gs_lr.score(test_corpus, test_label_names)\n",
    "print('Test Accuracy :', best_lr_test_score)\n",
    "# We get an overall test accuracy of approximately 77%, which is almost a 2.5%\n",
    "# improvement from the base logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let’s tune our top two SVM models—the regular Linear SVM model and the SVM with Stochastic Gradient Descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] tfidf__ngram_range=(1, 1), svm__C=0.01 ..........................\n",
      "[CV] ........... tfidf__ngram_range=(1, 1), svm__C=0.01, total=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] tfidf__ngram_range=(1, 1), svm__C=0.01 ..........................\n",
      "[CV] ........... tfidf__ngram_range=(1, 1), svm__C=0.01, total=   3.1s\n",
      "[CV] tfidf__ngram_range=(1, 1), svm__C=0.01 ..........................\n",
      "[CV] ........... tfidf__ngram_range=(1, 1), svm__C=0.01, total=   3.0s\n",
      "[CV] tfidf__ngram_range=(1, 1), svm__C=0.01 ..........................\n",
      "[CV] ........... tfidf__ngram_range=(1, 1), svm__C=0.01, total=   2.9s\n",
      "[CV] tfidf__ngram_range=(1, 1), svm__C=0.01 ..........................\n",
      "[CV] ........... tfidf__ngram_range=(1, 1), svm__C=0.01, total=   3.3s\n",
      "[CV] tfidf__ngram_range=(1, 2), svm__C=0.01 ..........................\n",
      "[CV] ........... tfidf__ngram_range=(1, 2), svm__C=0.01, total=  11.6s\n",
      "[CV] tfidf__ngram_range=(1, 2), svm__C=0.01 ..........................\n",
      "[CV] ........... tfidf__ngram_range=(1, 2), svm__C=0.01, total=  12.5s\n",
      "[CV] tfidf__ngram_range=(1, 2), svm__C=0.01 ..........................\n",
      "[CV] ........... tfidf__ngram_range=(1, 2), svm__C=0.01, total=  11.3s\n",
      "[CV] tfidf__ngram_range=(1, 2), svm__C=0.01 ..........................\n",
      "[CV] ........... tfidf__ngram_range=(1, 2), svm__C=0.01, total=  13.8s\n",
      "[CV] tfidf__ngram_range=(1, 2), svm__C=0.01 ..........................\n",
      "[CV] ........... tfidf__ngram_range=(1, 2), svm__C=0.01, total=  10.5s\n",
      "[CV] tfidf__ngram_range=(1, 1), svm__C=0.1 ...........................\n",
      "[CV] ............ tfidf__ngram_range=(1, 1), svm__C=0.1, total=   2.7s\n",
      "[CV] tfidf__ngram_range=(1, 1), svm__C=0.1 ...........................\n",
      "[CV] ............ tfidf__ngram_range=(1, 1), svm__C=0.1, total=   2.5s\n",
      "[CV] tfidf__ngram_range=(1, 1), svm__C=0.1 ...........................\n",
      "[CV] ............ tfidf__ngram_range=(1, 1), svm__C=0.1, total=   2.5s\n",
      "[CV] tfidf__ngram_range=(1, 1), svm__C=0.1 ...........................\n",
      "[CV] ............ tfidf__ngram_range=(1, 1), svm__C=0.1, total=   2.5s\n",
      "[CV] tfidf__ngram_range=(1, 1), svm__C=0.1 ...........................\n",
      "[CV] ............ tfidf__ngram_range=(1, 1), svm__C=0.1, total=   2.4s\n",
      "[CV] tfidf__ngram_range=(1, 2), svm__C=0.1 ...........................\n",
      "[CV] ............ tfidf__ngram_range=(1, 2), svm__C=0.1, total=  11.5s\n",
      "[CV] tfidf__ngram_range=(1, 2), svm__C=0.1 ...........................\n",
      "[CV] ............ tfidf__ngram_range=(1, 2), svm__C=0.1, total=  11.3s\n",
      "[CV] tfidf__ngram_range=(1, 2), svm__C=0.1 ...........................\n",
      "[CV] ............ tfidf__ngram_range=(1, 2), svm__C=0.1, total=  11.2s\n",
      "[CV] tfidf__ngram_range=(1, 2), svm__C=0.1 ...........................\n",
      "[CV] ............ tfidf__ngram_range=(1, 2), svm__C=0.1, total=  11.2s\n",
      "[CV] tfidf__ngram_range=(1, 2), svm__C=0.1 ...........................\n",
      "[CV] ............ tfidf__ngram_range=(1, 2), svm__C=0.1, total=  10.9s\n",
      "[CV] tfidf__ngram_range=(1, 1), svm__C=1 .............................\n",
      "[CV] .............. tfidf__ngram_range=(1, 1), svm__C=1, total=   2.9s\n",
      "[CV] tfidf__ngram_range=(1, 1), svm__C=1 .............................\n",
      "[CV] .............. tfidf__ngram_range=(1, 1), svm__C=1, total=   2.9s\n",
      "[CV] tfidf__ngram_range=(1, 1), svm__C=1 .............................\n",
      "[CV] .............. tfidf__ngram_range=(1, 1), svm__C=1, total=   2.9s\n",
      "[CV] tfidf__ngram_range=(1, 1), svm__C=1 .............................\n",
      "[CV] .............. tfidf__ngram_range=(1, 1), svm__C=1, total=   2.9s\n",
      "[CV] tfidf__ngram_range=(1, 1), svm__C=1 .............................\n",
      "[CV] .............. tfidf__ngram_range=(1, 1), svm__C=1, total=   2.9s\n",
      "[CV] tfidf__ngram_range=(1, 2), svm__C=1 .............................\n",
      "[CV] .............. tfidf__ngram_range=(1, 2), svm__C=1, total=  14.5s\n",
      "[CV] tfidf__ngram_range=(1, 2), svm__C=1 .............................\n",
      "[CV] .............. tfidf__ngram_range=(1, 2), svm__C=1, total=  14.4s\n",
      "[CV] tfidf__ngram_range=(1, 2), svm__C=1 .............................\n",
      "[CV] .............. tfidf__ngram_range=(1, 2), svm__C=1, total=  14.7s\n",
      "[CV] tfidf__ngram_range=(1, 2), svm__C=1 .............................\n",
      "[CV] .............. tfidf__ngram_range=(1, 2), svm__C=1, total=  14.4s\n",
      "[CV] tfidf__ngram_range=(1, 2), svm__C=1 .............................\n",
      "[CV] .............. tfidf__ngram_range=(1, 2), svm__C=1, total=  13.8s\n",
      "[CV] tfidf__ngram_range=(1, 1), svm__C=5 .............................\n",
      "[CV] .............. tfidf__ngram_range=(1, 1), svm__C=5, total=   4.8s\n",
      "[CV] tfidf__ngram_range=(1, 1), svm__C=5 .............................\n",
      "[CV] .............. tfidf__ngram_range=(1, 1), svm__C=5, total=   4.5s\n",
      "[CV] tfidf__ngram_range=(1, 1), svm__C=5 .............................\n",
      "[CV] .............. tfidf__ngram_range=(1, 1), svm__C=5, total=   4.8s\n",
      "[CV] tfidf__ngram_range=(1, 1), svm__C=5 .............................\n",
      "[CV] .............. tfidf__ngram_range=(1, 1), svm__C=5, total=   5.1s\n",
      "[CV] tfidf__ngram_range=(1, 1), svm__C=5 .............................\n",
      "[CV] .............. tfidf__ngram_range=(1, 1), svm__C=5, total=   4.7s\n",
      "[CV] tfidf__ngram_range=(1, 2), svm__C=5 .............................\n",
      "[CV] .............. tfidf__ngram_range=(1, 2), svm__C=5, total=  30.4s\n",
      "[CV] tfidf__ngram_range=(1, 2), svm__C=5 .............................\n",
      "[CV] .............. tfidf__ngram_range=(1, 2), svm__C=5, total=  26.4s\n",
      "[CV] tfidf__ngram_range=(1, 2), svm__C=5 .............................\n",
      "[CV] .............. tfidf__ngram_range=(1, 2), svm__C=5, total=  28.3s\n",
      "[CV] tfidf__ngram_range=(1, 2), svm__C=5 .............................\n",
      "[CV] .............. tfidf__ngram_range=(1, 2), svm__C=5, total=  33.5s\n",
      "[CV] tfidf__ngram_range=(1, 2), svm__C=5 .............................\n",
      "[CV] .............. tfidf__ngram_range=(1, 2), svm__C=5, total=  31.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:  8.3min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svm_pipeline = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                        ('svm', LinearSVC(random_state=42))\n",
    "                       ])\n",
    "\n",
    "param_grid = {'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "              'svm__C': [0.01, 0.1, 1, 5]\n",
    "}\n",
    "\n",
    "gs_svm = GridSearchCV(svm_pipeline, param_grid, cv=5, verbose=2)\n",
    "gs_svm = gs_svm.fit(train_corpus, train_label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('tfidf',\n",
       "   TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "           dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "           lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "           ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "           stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "           token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "           vocabulary=None)),\n",
       "  ('svm', LinearSVC(C=5, class_weight=None, dual=True, fit_intercept=True,\n",
       "        intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "        multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "        verbose=0))],\n",
       " 'svm': LinearSVC(C=5, class_weight=None, dual=True, fit_intercept=True,\n",
       "      intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "      multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "      verbose=0),\n",
       " 'svm__C': 5,\n",
       " 'svm__class_weight': None,\n",
       " 'svm__dual': True,\n",
       " 'svm__fit_intercept': True,\n",
       " 'svm__intercept_scaling': 1,\n",
       " 'svm__loss': 'squared_hinge',\n",
       " 'svm__max_iter': 1000,\n",
       " 'svm__multi_class': 'ovr',\n",
       " 'svm__penalty': 'l2',\n",
       " 'svm__random_state': 42,\n",
       " 'svm__tol': 0.0001,\n",
       " 'svm__verbose': 0,\n",
       " 'tfidf': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "         stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "         token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "         vocabulary=None),\n",
       " 'tfidf__analyzer': 'word',\n",
       " 'tfidf__binary': False,\n",
       " 'tfidf__decode_error': 'strict',\n",
       " 'tfidf__dtype': numpy.int64,\n",
       " 'tfidf__encoding': 'utf-8',\n",
       " 'tfidf__input': 'content',\n",
       " 'tfidf__lowercase': True,\n",
       " 'tfidf__max_df': 1.0,\n",
       " 'tfidf__max_features': None,\n",
       " 'tfidf__min_df': 1,\n",
       " 'tfidf__ngram_range': (1, 2),\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__preprocessor': None,\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__stop_words': None,\n",
       " 'tfidf__strip_accents': None,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tfidf__tokenizer': None,\n",
       " 'tfidf__use_idf': True,\n",
       " 'tfidf__vocabulary': None}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svm.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.77685813607\n"
     ]
    }
   ],
   "source": [
    "best_svm_test_score = gs_svm.score(test_corpus, test_label_names)\n",
    "print('Test Accuracy :', best_svm_test_score)\n",
    "# This is definitely the highest overall accuracy we have obtained so far! However, not a\n",
    "# huge improvement from the default linear SVM model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] tfidf__ngram_range=(1, 1), sgd__alpha=1e-07 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 1), sgd__alpha=1e-07, total=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] tfidf__ngram_range=(1, 1), sgd__alpha=1e-07 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 1), sgd__alpha=1e-07, total=   2.3s\n",
      "[CV] tfidf__ngram_range=(1, 1), sgd__alpha=1e-07 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 1), sgd__alpha=1e-07, total=   3.4s\n",
      "[CV] tfidf__ngram_range=(1, 1), sgd__alpha=1e-07 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 1), sgd__alpha=1e-07, total=   3.0s\n",
      "[CV] tfidf__ngram_range=(1, 1), sgd__alpha=1e-07 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 1), sgd__alpha=1e-07, total=   2.3s\n",
      "[CV] tfidf__ngram_range=(1, 2), sgd__alpha=1e-07 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 2), sgd__alpha=1e-07, total=   9.0s\n",
      "[CV] tfidf__ngram_range=(1, 2), sgd__alpha=1e-07 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 2), sgd__alpha=1e-07, total=  10.2s\n",
      "[CV] tfidf__ngram_range=(1, 2), sgd__alpha=1e-07 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 2), sgd__alpha=1e-07, total=   9.8s\n",
      "[CV] tfidf__ngram_range=(1, 2), sgd__alpha=1e-07 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 2), sgd__alpha=1e-07, total=  11.0s\n",
      "[CV] tfidf__ngram_range=(1, 2), sgd__alpha=1e-07 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 2), sgd__alpha=1e-07, total=  10.7s\n",
      "[CV] tfidf__ngram_range=(1, 1), sgd__alpha=1e-06 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 1), sgd__alpha=1e-06, total=   2.2s\n",
      "[CV] tfidf__ngram_range=(1, 1), sgd__alpha=1e-06 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 1), sgd__alpha=1e-06, total=   2.1s\n",
      "[CV] tfidf__ngram_range=(1, 1), sgd__alpha=1e-06 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 1), sgd__alpha=1e-06, total=   2.1s\n",
      "[CV] tfidf__ngram_range=(1, 1), sgd__alpha=1e-06 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 1), sgd__alpha=1e-06, total=   2.1s\n",
      "[CV] tfidf__ngram_range=(1, 1), sgd__alpha=1e-06 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 1), sgd__alpha=1e-06, total=   2.0s\n",
      "[CV] tfidf__ngram_range=(1, 2), sgd__alpha=1e-06 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 2), sgd__alpha=1e-06, total=   9.7s\n",
      "[CV] tfidf__ngram_range=(1, 2), sgd__alpha=1e-06 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 2), sgd__alpha=1e-06, total=  13.4s\n",
      "[CV] tfidf__ngram_range=(1, 2), sgd__alpha=1e-06 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 2), sgd__alpha=1e-06, total=  10.1s\n",
      "[CV] tfidf__ngram_range=(1, 2), sgd__alpha=1e-06 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 2), sgd__alpha=1e-06, total=  11.8s\n",
      "[CV] tfidf__ngram_range=(1, 2), sgd__alpha=1e-06 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 2), sgd__alpha=1e-06, total=  13.6s\n",
      "[CV] tfidf__ngram_range=(1, 1), sgd__alpha=1e-05 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 1), sgd__alpha=1e-05, total=   2.8s\n",
      "[CV] tfidf__ngram_range=(1, 1), sgd__alpha=1e-05 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 1), sgd__alpha=1e-05, total=   2.9s\n",
      "[CV] tfidf__ngram_range=(1, 1), sgd__alpha=1e-05 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 1), sgd__alpha=1e-05, total=   3.6s\n",
      "[CV] tfidf__ngram_range=(1, 1), sgd__alpha=1e-05 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 1), sgd__alpha=1e-05, total=   3.0s\n",
      "[CV] tfidf__ngram_range=(1, 1), sgd__alpha=1e-05 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 1), sgd__alpha=1e-05, total=   2.8s\n",
      "[CV] tfidf__ngram_range=(1, 2), sgd__alpha=1e-05 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 2), sgd__alpha=1e-05, total=  13.4s\n",
      "[CV] tfidf__ngram_range=(1, 2), sgd__alpha=1e-05 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 2), sgd__alpha=1e-05, total=  13.9s\n",
      "[CV] tfidf__ngram_range=(1, 2), sgd__alpha=1e-05 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 2), sgd__alpha=1e-05, total=  11.3s\n",
      "[CV] tfidf__ngram_range=(1, 2), sgd__alpha=1e-05 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 2), sgd__alpha=1e-05, total=  11.0s\n",
      "[CV] tfidf__ngram_range=(1, 2), sgd__alpha=1e-05 .....................\n",
      "[CV] ...... tfidf__ngram_range=(1, 2), sgd__alpha=1e-05, total=  11.0s\n",
      "[CV] tfidf__ngram_range=(1, 1), sgd__alpha=0.0001 ....................\n",
      "[CV] ..... tfidf__ngram_range=(1, 1), sgd__alpha=0.0001, total=   2.3s\n",
      "[CV] tfidf__ngram_range=(1, 1), sgd__alpha=0.0001 ....................\n",
      "[CV] ..... tfidf__ngram_range=(1, 1), sgd__alpha=0.0001, total=   2.3s\n",
      "[CV] tfidf__ngram_range=(1, 1), sgd__alpha=0.0001 ....................\n",
      "[CV] ..... tfidf__ngram_range=(1, 1), sgd__alpha=0.0001, total=   2.3s\n",
      "[CV] tfidf__ngram_range=(1, 1), sgd__alpha=0.0001 ....................\n",
      "[CV] ..... tfidf__ngram_range=(1, 1), sgd__alpha=0.0001, total=   2.4s\n",
      "[CV] tfidf__ngram_range=(1, 1), sgd__alpha=0.0001 ....................\n",
      "[CV] ..... tfidf__ngram_range=(1, 1), sgd__alpha=0.0001, total=   2.3s\n",
      "[CV] tfidf__ngram_range=(1, 2), sgd__alpha=0.0001 ....................\n",
      "[CV] ..... tfidf__ngram_range=(1, 2), sgd__alpha=0.0001, total=  10.8s\n",
      "[CV] tfidf__ngram_range=(1, 2), sgd__alpha=0.0001 ....................\n",
      "[CV] ..... tfidf__ngram_range=(1, 2), sgd__alpha=0.0001, total=  10.7s\n",
      "[CV] tfidf__ngram_range=(1, 2), sgd__alpha=0.0001 ....................\n",
      "[CV] ..... tfidf__ngram_range=(1, 2), sgd__alpha=0.0001, total=  11.6s\n",
      "[CV] tfidf__ngram_range=(1, 2), sgd__alpha=0.0001 ....................\n",
      "[CV] ..... tfidf__ngram_range=(1, 2), sgd__alpha=0.0001, total=  11.3s\n",
      "[CV] tfidf__ngram_range=(1, 2), sgd__alpha=0.0001 ....................\n",
      "[CV] ..... tfidf__ngram_range=(1, 2), sgd__alpha=0.0001, total=  13.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:  6.6min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "sgd_pipeline = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                        ('sgd', SGDClassifier(random_state=42))\n",
    "                       ])\n",
    "\n",
    "param_grid = {'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "              'sgd__alpha': [1e-7, 1e-6, 1e-5, 1e-4]\n",
    "}\n",
    "\n",
    "gs_sgd = GridSearchCV(sgd_pipeline, param_grid, cv=5, verbose=2)\n",
    "gs_sgd = gs_sgd.fit(train_corpus, train_label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'sgd': SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "        eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "        learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "        n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
       "        tol=None, verbose=0, warm_start=False),\n",
       " 'sgd__alpha': 0.0001,\n",
       " 'sgd__average': False,\n",
       " 'sgd__class_weight': None,\n",
       " 'sgd__epsilon': 0.1,\n",
       " 'sgd__eta0': 0.0,\n",
       " 'sgd__fit_intercept': True,\n",
       " 'sgd__l1_ratio': 0.15,\n",
       " 'sgd__learning_rate': 'optimal',\n",
       " 'sgd__loss': 'hinge',\n",
       " 'sgd__max_iter': None,\n",
       " 'sgd__n_iter': None,\n",
       " 'sgd__n_jobs': 1,\n",
       " 'sgd__penalty': 'l2',\n",
       " 'sgd__power_t': 0.5,\n",
       " 'sgd__random_state': 42,\n",
       " 'sgd__shuffle': True,\n",
       " 'sgd__tol': None,\n",
       " 'sgd__verbose': 0,\n",
       " 'sgd__warm_start': False,\n",
       " 'steps': [('tfidf',\n",
       "   TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "           dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "           lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "           ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "           stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "           token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "           vocabulary=None)),\n",
       "  ('sgd',\n",
       "   SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "          eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "          learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "          n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
       "          tol=None, verbose=0, warm_start=False))],\n",
       " 'tfidf': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "         stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "         token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "         vocabulary=None),\n",
       " 'tfidf__analyzer': 'word',\n",
       " 'tfidf__binary': False,\n",
       " 'tfidf__decode_error': 'strict',\n",
       " 'tfidf__dtype': numpy.int64,\n",
       " 'tfidf__encoding': 'utf-8',\n",
       " 'tfidf__input': 'content',\n",
       " 'tfidf__lowercase': True,\n",
       " 'tfidf__max_df': 1.0,\n",
       " 'tfidf__max_features': None,\n",
       " 'tfidf__min_df': 1,\n",
       " 'tfidf__ngram_range': (1, 2),\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__preprocessor': None,\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__stop_words': None,\n",
       " 'tfidf__strip_accents': None,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tfidf__tokenizer': None,\n",
       " 'tfidf__use_idf': True,\n",
       " 'tfidf__vocabulary': None}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_sgd.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.768415825195\n"
     ]
    }
   ],
   "source": [
    "best_sgd_test_score = gs_sgd.score(test_corpus, test_label_names)\n",
    "print('Test Accuracy :', best_sgd_test_score)\n",
    "# The SVM with SGD gives us a tuned model accuracy of 76.8%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Evaluation\n",
    "Choosing the best model for deployment depends on a number of factors, like the model speed, accuracy, ease of use, understanding, and so on.\n",
    "The Naïve Bayes model is the fastest to train and, even though the SVM model\n",
    "might be slightly better on the test dataset in terms of accuracy, SVMs are notoriously slow and often hard to scale. Let’s take a detailed performance evaluation of our best, tuned Naïve Bayes model on the test dataset. We use our nifty model_evaluation_utils module for the purpose of model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_evaluation_utils as meu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7735\n",
      "Precision: 0.7825\n",
      "Recall: 0.7735\n",
      "F1 Score: 0.7696\n"
     ]
    }
   ],
   "source": [
    "mnb_predictions = gs_mnb.predict(test_corpus)\n",
    "unique_classes = list(set(test_label_names))\n",
    "meu.get_metrics(true_labels=test_label_names, predicted_labels=mnb_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      " comp.os.ms-windows.misc       0.76      0.72      0.74       315\n",
      "      talk.politics.misc       0.72      0.68      0.70       244\n",
      "           comp.graphics       0.64      0.75      0.69       289\n",
      "          comp.windows.x       0.79      0.84      0.81       287\n",
      "      talk.religion.misc       0.67      0.21      0.32       199\n",
      "comp.sys.ibm.pc.hardware       0.69      0.76      0.72       324\n",
      "   comp.sys.mac.hardware       0.78      0.77      0.77       295\n",
      "               sci.crypt       0.79      0.85      0.82       302\n",
      "   talk.politics.mideast       0.85      0.87      0.86       326\n",
      "            misc.forsale       0.83      0.77      0.80       314\n",
      "                 sci.med       0.88      0.88      0.88       322\n",
      "         rec.motorcycles       0.88      0.74      0.80       351\n",
      "         sci.electronics       0.80      0.72      0.76       307\n",
      "        rec.sport.hockey       0.88      0.92      0.90       308\n",
      "      talk.politics.guns       0.65      0.81      0.72       281\n",
      "               sci.space       0.84      0.81      0.83       324\n",
      "      rec.sport.baseball       0.94      0.88      0.91       336\n",
      "             alt.atheism       0.80      0.57      0.67       268\n",
      "               rec.autos       0.82      0.74      0.78       328\n",
      "  soc.religion.christian       0.57      0.92      0.70       321\n",
      "\n",
      "               micro avg       0.77      0.77      0.77      6041\n",
      "               macro avg       0.78      0.76      0.76      6041\n",
      "            weighted avg       0.78      0.77      0.77      6041\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It is good to see good consistency with the classification metrics. Besides seeing the\n",
    "# holistic view of model performance metrics, often a more granular view into per-class\n",
    "# model performance metrics helps.\n",
    "meu.display_classification_report(true_labels=test_label_names, \n",
    "                                  predicted_labels=mnb_predictions, classes=unique_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label Name</th>\n",
       "      <th>Label Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>comp.windows.x</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>misc.forsale</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rec.autos</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rec.motorcycles</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sci.electronics</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sci.med</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sci.space</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>soc.religion.christian</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>talk.politics.guns</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>talk.politics.mideast</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>talk.politics.misc</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Label Name  Label Number\n",
       "0                alt.atheism             0\n",
       "1              comp.graphics             1\n",
       "2    comp.os.ms-windows.misc             2\n",
       "3   comp.sys.ibm.pc.hardware             3\n",
       "4      comp.sys.mac.hardware             4\n",
       "5             comp.windows.x             5\n",
       "6               misc.forsale             6\n",
       "7                  rec.autos             7\n",
       "8            rec.motorcycles             8\n",
       "9         rec.sport.baseball             9\n",
       "10          rec.sport.hockey            10\n",
       "11                 sci.crypt            11\n",
       "12           sci.electronics            12\n",
       "13                   sci.med            13\n",
       "14                 sci.space            14\n",
       "15    soc.religion.christian            15\n",
       "16        talk.politics.guns            16\n",
       "17     talk.politics.mideast            17\n",
       "18        talk.politics.misc            18\n",
       "19        talk.religion.misc            19"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This gives us a nice overview into the model performance for each newsgroup class\n",
    "# and interestingly some categories like religion, Christianity, and atheism have slightly\n",
    "# lower performance. Could it be that the model is getting some of these mixed up? The\n",
    "# confusion matrix is a great way to test this assumption.\n",
    "label_data_map = {v:k for k, v in data_labels_map.items()}\n",
    "label_map_df = pd.DataFrame(list(label_data_map.items()), columns=['Label Name', 'Label Number'])\n",
    "label_map_df\n",
    "# Mapping between class label names and numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"20\" halign=\"left\">Predicted:</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"20\" valign=\"top\">Actual:</th>\n",
       "      <th>0</th>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>218</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>226</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>245</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>227</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>241</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>242</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>242</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>260</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>297</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>282</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>222</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>284</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>264</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>295</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>227</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>284</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>166</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Predicted:                                                         \\\n",
       "                   0    1    2    3    4    5    6    7    8    9    10   11   \n",
       "Actual: 0         153    1    0    0    0    2    0    3    2    1    3    1   \n",
       "        1           2  218   10   11    5   16    4    0    2    2    0    4   \n",
       "        2           1   22  226   24    6   15    3    1    0    1    1    3   \n",
       "        3           1   15   22  245   20    2    9    3    0    0    0    1   \n",
       "        4           0    7   10   22  227    5    5    1    0    0    1    9   \n",
       "        5           1   26   10    4    0  241    1    0    0    0    0    1   \n",
       "        6           0    2    4   17   13    0  242    7    1    0    1    3   \n",
       "        7           2    3    3    3    3    2    9  242   16    1    0    4   \n",
       "        8           0    3    1    0    2    3    6   25  260    2    7    2   \n",
       "        9           0    3    0    2    2    4    0    0    1  297   12    6   \n",
       "        10          2    0    0    0    0    3    2    1    1    5  282    1   \n",
       "        11          0    5    4    0    4    1    0    1    2    1    3  256   \n",
       "        12          0   14    3   22    5    2    7    5    0    0    1    9   \n",
       "        13          1    8    0    0    0    1    0    3    0    0    0    0   \n",
       "        14          2   11    2    1    2    2    2    2    2    2    0    4   \n",
       "        15          4    2    1    0    2    1    0    0    0    1    0    0   \n",
       "        16          3    0    0    1    1    1    0    0    4    1    2    9   \n",
       "        17          2    1    1    1    0    0    0    0    4    1    0    4   \n",
       "        18          0    1    1    0    0    1    0    1    2    1    5    5   \n",
       "        19         18    0    1    0    0    4    1    1    0    1    2    4   \n",
       "\n",
       "                                                   \n",
       "             12   13   14   15   16   17   18  19  \n",
       "Actual: 0     0    1    4   57   10   15    5  10  \n",
       "        1     2    0    9    2    1    0    1   0  \n",
       "        2     4    3    3    1    1    0    0   0  \n",
       "        3     5    0    0    0    1    0    0   0  \n",
       "        4     4    0    0    2    0    0    1   1  \n",
       "        5     0    0    1    1    1    0    0   0  \n",
       "        6     8    1    5    4    3    2    1   0  \n",
       "        7     9    5    3    4   12    3    3   1  \n",
       "        8     3    6    4    8   10    1    8   0  \n",
       "        9     0    1    1    3    3    1    0   0  \n",
       "        10    1    2    1    1    1    2    3   0  \n",
       "        11    3    0    1    2   13    2    4   0  \n",
       "        12  222    5    4    3    2    1    2   0  \n",
       "        13    6  284    5    7    2    2    3   0  \n",
       "        14    5    5  264    4    8    2    4   0  \n",
       "        15    0    3    1  295    4    3    2   2  \n",
       "        16    3    0    2    6  227    6   12   3  \n",
       "        17    0    1    1    9    5  284   11   1  \n",
       "        18    0    2    5   14   31    6  166   3  \n",
       "        19    2    4    1   93   15    4    6  42  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now build a confusion matrix to show the correct and misclassified instances\n",
    "# of each class label, which we represent by numbers for display purposes, due to the long names.\n",
    "unique_class_nums = label_map_df['Label Number'].values\n",
    "mnb_prediction_class_nums = [label_data_map[item] for item in mnb_predictions]\n",
    "meu.display_confusion_matrix_pretty(true_labels=test_label_nums, \n",
    "                                   predicted_labels=mnb_prediction_class_nums, classes=unique_class_nums)\n",
    "# The diagonal of our confusion matrix has the meat of the numbers, which indicates\n",
    "# that most of our predictions match the actual class labels\n",
    "# Interestingly, class labels 0, 15, and 19 seem to have a lot of misclassifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"20\" halign=\"left\">Predicted:</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>alt.atheism</th>\n",
       "      <th>comp.graphics</th>\n",
       "      <th>comp.os.ms-windows.misc</th>\n",
       "      <th>comp.sys.ibm.pc.hardware</th>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <th>comp.windows.x</th>\n",
       "      <th>misc.forsale</th>\n",
       "      <th>rec.autos</th>\n",
       "      <th>rec.motorcycles</th>\n",
       "      <th>rec.sport.baseball</th>\n",
       "      <th>rec.sport.hockey</th>\n",
       "      <th>sci.crypt</th>\n",
       "      <th>sci.electronics</th>\n",
       "      <th>sci.med</th>\n",
       "      <th>sci.space</th>\n",
       "      <th>soc.religion.christian</th>\n",
       "      <th>talk.politics.guns</th>\n",
       "      <th>talk.politics.mideast</th>\n",
       "      <th>talk.politics.misc</th>\n",
       "      <th>talk.religion.misc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"20\" valign=\"top\">Actual:</th>\n",
       "      <th>alt.atheism</th>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.graphics</th>\n",
       "      <td>2</td>\n",
       "      <td>218</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.os.ms-windows.misc</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>226</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.ibm.pc.hardware</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>245</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>227</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.windows.x</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>241</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misc.forsale</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>242</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.autos</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>242</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.motorcycles</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>260</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.sport.baseball</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>297</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.sport.hockey</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>282</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.crypt</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.electronics</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>222</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.med</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>284</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.space</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>264</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soc.religion.christian</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>295</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk.politics.guns</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>227</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk.politics.mideast</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>284</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk.politics.misc</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>166</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk.religion.misc</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Predicted:                \\\n",
       "                                 alt.atheism comp.graphics   \n",
       "Actual: alt.atheism                      153             1   \n",
       "        comp.graphics                      2           218   \n",
       "        comp.os.ms-windows.misc            1            22   \n",
       "        comp.sys.ibm.pc.hardware           1            15   \n",
       "        comp.sys.mac.hardware              0             7   \n",
       "        comp.windows.x                     1            26   \n",
       "        misc.forsale                       0             2   \n",
       "        rec.autos                          2             3   \n",
       "        rec.motorcycles                    0             3   \n",
       "        rec.sport.baseball                 0             3   \n",
       "        rec.sport.hockey                   2             0   \n",
       "        sci.crypt                          0             5   \n",
       "        sci.electronics                    0            14   \n",
       "        sci.med                            1             8   \n",
       "        sci.space                          2            11   \n",
       "        soc.religion.christian             4             2   \n",
       "        talk.politics.guns                 3             0   \n",
       "        talk.politics.mideast              2             1   \n",
       "        talk.politics.misc                 0             1   \n",
       "        talk.religion.misc                18             0   \n",
       "\n",
       "                                                          \\\n",
       "                                 comp.os.ms-windows.misc   \n",
       "Actual: alt.atheism                                    0   \n",
       "        comp.graphics                                 10   \n",
       "        comp.os.ms-windows.misc                      226   \n",
       "        comp.sys.ibm.pc.hardware                      22   \n",
       "        comp.sys.mac.hardware                         10   \n",
       "        comp.windows.x                                10   \n",
       "        misc.forsale                                   4   \n",
       "        rec.autos                                      3   \n",
       "        rec.motorcycles                                1   \n",
       "        rec.sport.baseball                             0   \n",
       "        rec.sport.hockey                               0   \n",
       "        sci.crypt                                      4   \n",
       "        sci.electronics                                3   \n",
       "        sci.med                                        0   \n",
       "        sci.space                                      2   \n",
       "        soc.religion.christian                         1   \n",
       "        talk.politics.guns                             0   \n",
       "        talk.politics.mideast                          1   \n",
       "        talk.politics.misc                             1   \n",
       "        talk.religion.misc                             1   \n",
       "\n",
       "                                                           \\\n",
       "                                 comp.sys.ibm.pc.hardware   \n",
       "Actual: alt.atheism                                     0   \n",
       "        comp.graphics                                  11   \n",
       "        comp.os.ms-windows.misc                        24   \n",
       "        comp.sys.ibm.pc.hardware                      245   \n",
       "        comp.sys.mac.hardware                          22   \n",
       "        comp.windows.x                                  4   \n",
       "        misc.forsale                                   17   \n",
       "        rec.autos                                       3   \n",
       "        rec.motorcycles                                 0   \n",
       "        rec.sport.baseball                              2   \n",
       "        rec.sport.hockey                                0   \n",
       "        sci.crypt                                       0   \n",
       "        sci.electronics                                22   \n",
       "        sci.med                                         0   \n",
       "        sci.space                                       1   \n",
       "        soc.religion.christian                          0   \n",
       "        talk.politics.guns                              1   \n",
       "        talk.politics.mideast                           1   \n",
       "        talk.politics.misc                              0   \n",
       "        talk.religion.misc                              0   \n",
       "\n",
       "                                                                       \\\n",
       "                                 comp.sys.mac.hardware comp.windows.x   \n",
       "Actual: alt.atheism                                  0              2   \n",
       "        comp.graphics                                5             16   \n",
       "        comp.os.ms-windows.misc                      6             15   \n",
       "        comp.sys.ibm.pc.hardware                    20              2   \n",
       "        comp.sys.mac.hardware                      227              5   \n",
       "        comp.windows.x                               0            241   \n",
       "        misc.forsale                                13              0   \n",
       "        rec.autos                                    3              2   \n",
       "        rec.motorcycles                              2              3   \n",
       "        rec.sport.baseball                           2              4   \n",
       "        rec.sport.hockey                             0              3   \n",
       "        sci.crypt                                    4              1   \n",
       "        sci.electronics                              5              2   \n",
       "        sci.med                                      0              1   \n",
       "        sci.space                                    2              2   \n",
       "        soc.religion.christian                       2              1   \n",
       "        talk.politics.guns                           1              1   \n",
       "        talk.politics.mideast                        0              0   \n",
       "        talk.politics.misc                           0              1   \n",
       "        talk.religion.misc                           0              4   \n",
       "\n",
       "                                                                         \\\n",
       "                                 misc.forsale rec.autos rec.motorcycles   \n",
       "Actual: alt.atheism                         0         3               2   \n",
       "        comp.graphics                       4         0               2   \n",
       "        comp.os.ms-windows.misc             3         1               0   \n",
       "        comp.sys.ibm.pc.hardware            9         3               0   \n",
       "        comp.sys.mac.hardware               5         1               0   \n",
       "        comp.windows.x                      1         0               0   \n",
       "        misc.forsale                      242         7               1   \n",
       "        rec.autos                           9       242              16   \n",
       "        rec.motorcycles                     6        25             260   \n",
       "        rec.sport.baseball                  0         0               1   \n",
       "        rec.sport.hockey                    2         1               1   \n",
       "        sci.crypt                           0         1               2   \n",
       "        sci.electronics                     7         5               0   \n",
       "        sci.med                             0         3               0   \n",
       "        sci.space                           2         2               2   \n",
       "        soc.religion.christian              0         0               0   \n",
       "        talk.politics.guns                  0         0               4   \n",
       "        talk.politics.mideast               0         0               4   \n",
       "        talk.politics.misc                  0         1               2   \n",
       "        talk.religion.misc                  1         1               0   \n",
       "\n",
       "                                                                      \\\n",
       "                                 rec.sport.baseball rec.sport.hockey   \n",
       "Actual: alt.atheism                               1                3   \n",
       "        comp.graphics                             2                0   \n",
       "        comp.os.ms-windows.misc                   1                1   \n",
       "        comp.sys.ibm.pc.hardware                  0                0   \n",
       "        comp.sys.mac.hardware                     0                1   \n",
       "        comp.windows.x                            0                0   \n",
       "        misc.forsale                              0                1   \n",
       "        rec.autos                                 1                0   \n",
       "        rec.motorcycles                           2                7   \n",
       "        rec.sport.baseball                      297               12   \n",
       "        rec.sport.hockey                          5              282   \n",
       "        sci.crypt                                 1                3   \n",
       "        sci.electronics                           0                1   \n",
       "        sci.med                                   0                0   \n",
       "        sci.space                                 2                0   \n",
       "        soc.religion.christian                    1                0   \n",
       "        talk.politics.guns                        1                2   \n",
       "        talk.politics.mideast                     1                0   \n",
       "        talk.politics.misc                        1                5   \n",
       "        talk.religion.misc                        1                2   \n",
       "\n",
       "                                                                              \\\n",
       "                                 sci.crypt sci.electronics sci.med sci.space   \n",
       "Actual: alt.atheism                      1               0       1         4   \n",
       "        comp.graphics                    4               2       0         9   \n",
       "        comp.os.ms-windows.misc          3               4       3         3   \n",
       "        comp.sys.ibm.pc.hardware         1               5       0         0   \n",
       "        comp.sys.mac.hardware            9               4       0         0   \n",
       "        comp.windows.x                   1               0       0         1   \n",
       "        misc.forsale                     3               8       1         5   \n",
       "        rec.autos                        4               9       5         3   \n",
       "        rec.motorcycles                  2               3       6         4   \n",
       "        rec.sport.baseball               6               0       1         1   \n",
       "        rec.sport.hockey                 1               1       2         1   \n",
       "        sci.crypt                      256               3       0         1   \n",
       "        sci.electronics                  9             222       5         4   \n",
       "        sci.med                          0               6     284         5   \n",
       "        sci.space                        4               5       5       264   \n",
       "        soc.religion.christian           0               0       3         1   \n",
       "        talk.politics.guns               9               3       0         2   \n",
       "        talk.politics.mideast            4               0       1         1   \n",
       "        talk.politics.misc               5               0       2         5   \n",
       "        talk.religion.misc               4               2       4         1   \n",
       "\n",
       "                                                                            \\\n",
       "                                 soc.religion.christian talk.politics.guns   \n",
       "Actual: alt.atheism                                  57                 10   \n",
       "        comp.graphics                                 2                  1   \n",
       "        comp.os.ms-windows.misc                       1                  1   \n",
       "        comp.sys.ibm.pc.hardware                      0                  1   \n",
       "        comp.sys.mac.hardware                         2                  0   \n",
       "        comp.windows.x                                1                  1   \n",
       "        misc.forsale                                  4                  3   \n",
       "        rec.autos                                     4                 12   \n",
       "        rec.motorcycles                               8                 10   \n",
       "        rec.sport.baseball                            3                  3   \n",
       "        rec.sport.hockey                              1                  1   \n",
       "        sci.crypt                                     2                 13   \n",
       "        sci.electronics                               3                  2   \n",
       "        sci.med                                       7                  2   \n",
       "        sci.space                                     4                  8   \n",
       "        soc.religion.christian                      295                  4   \n",
       "        talk.politics.guns                            6                227   \n",
       "        talk.politics.mideast                         9                  5   \n",
       "        talk.politics.misc                           14                 31   \n",
       "        talk.religion.misc                           93                 15   \n",
       "\n",
       "                                                                           \\\n",
       "                                 talk.politics.mideast talk.politics.misc   \n",
       "Actual: alt.atheism                                 15                  5   \n",
       "        comp.graphics                                0                  1   \n",
       "        comp.os.ms-windows.misc                      0                  0   \n",
       "        comp.sys.ibm.pc.hardware                     0                  0   \n",
       "        comp.sys.mac.hardware                        0                  1   \n",
       "        comp.windows.x                               0                  0   \n",
       "        misc.forsale                                 2                  1   \n",
       "        rec.autos                                    3                  3   \n",
       "        rec.motorcycles                              1                  8   \n",
       "        rec.sport.baseball                           1                  0   \n",
       "        rec.sport.hockey                             2                  3   \n",
       "        sci.crypt                                    2                  4   \n",
       "        sci.electronics                              1                  2   \n",
       "        sci.med                                      2                  3   \n",
       "        sci.space                                    2                  4   \n",
       "        soc.religion.christian                       3                  2   \n",
       "        talk.politics.guns                           6                 12   \n",
       "        talk.politics.mideast                      284                 11   \n",
       "        talk.politics.misc                           6                166   \n",
       "        talk.religion.misc                           4                  6   \n",
       "\n",
       "                                                     \n",
       "                                 talk.religion.misc  \n",
       "Actual: alt.atheism                              10  \n",
       "        comp.graphics                             0  \n",
       "        comp.os.ms-windows.misc                   0  \n",
       "        comp.sys.ibm.pc.hardware                  0  \n",
       "        comp.sys.mac.hardware                     1  \n",
       "        comp.windows.x                            0  \n",
       "        misc.forsale                              0  \n",
       "        rec.autos                                 1  \n",
       "        rec.motorcycles                           0  \n",
       "        rec.sport.baseball                        0  \n",
       "        rec.sport.hockey                          0  \n",
       "        sci.crypt                                 0  \n",
       "        sci.electronics                           0  \n",
       "        sci.med                                   0  \n",
       "        sci.space                                 0  \n",
       "        soc.religion.christian                    2  \n",
       "        talk.politics.guns                        3  \n",
       "        talk.politics.mideast                     1  \n",
       "        talk.politics.misc                        3  \n",
       "        talk.religion.misc                       42  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_classes = label_map_df['Label Name'].values\n",
    "meu.display_confusion_matrix_pretty(true_labels=test_label_names, \n",
    "                                    predicted_labels=mnb_predictions, classes=unique_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label Name</th>\n",
       "      <th>Label Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>soc.religion.christian</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Label Name  Label Number\n",
       "0              alt.atheism             0\n",
       "15  soc.religion.christian            15\n",
       "19      talk.religion.misc            19"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map_df[label_map_df['Label Number'].isin([0, 15, 19])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4105, 12650,  7039, ...,  4772,  7803,  9616])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx, test_idx = train_test_split(np.array(range(len(data_df['Article']))), test_size=0.33, random_state=42)\n",
    "test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Clean Article</th>\n",
       "      <th>Target Label</th>\n",
       "      <th>Target Name</th>\n",
       "      <th>Predicted Name</th>\n",
       "      <th>Predicted Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4105</th>\n",
       "      <td>Just a little nitpicking. Wasn't it the government that required\\r\\na standard railway gauge ? D...</td>\n",
       "      <td>little nitpicking not government require standard railway gauge not improve thing please not mis...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0.975658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12650</th>\n",
       "      <td>\\r\\nIt means that the EFF's public stance is complicated with issues irrelevant\\r\\nto the encryp...</td>\n",
       "      <td>mean eff public stance complicate issue irrelevant encryption issue per se may well people care ...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0.988600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7039</th>\n",
       "      <td>\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nSo after I've flashed my lights at the chap in front and he doesn't\\r\\n'pass...</td>\n",
       "      <td>flash light chap front not pass next major highway lane direction keep extreme right block folk ...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "      <td>0.729504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310</th>\n",
       "      <td>: I think most of the problems mainly arose from Manager Gene Mauch's\\r\\n: ineptitude in managin...</td>\n",
       "      <td>think problem mainly arise manager gene mauchs ineptitude manage pitching staff stretch abuse ji...</td>\n",
       "      <td>9</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>0.999942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16360</th>\n",
       "      <td>OK... quick scenario... you're at home, not bothering anybody... next thing you\\r\\nknow, somebod...</td>\n",
       "      <td>ok quick scenario home not bother anybody next thing know somebody come crash upstairs window he...</td>\n",
       "      <td>16</td>\n",
       "      <td>talk.politics.guns</td>\n",
       "      <td>talk.politics.guns</td>\n",
       "      <td>0.998837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   Article  \\\n",
       "4105   Just a little nitpicking. Wasn't it the government that required\\r\\na standard railway gauge ? D...   \n",
       "12650  \\r\\nIt means that the EFF's public stance is complicated with issues irrelevant\\r\\nto the encryp...   \n",
       "7039   \\r\\n\\r\\n\\r\\n\\r\\n\\r\\nSo after I've flashed my lights at the chap in front and he doesn't\\r\\n'pass...   \n",
       "3310   : I think most of the problems mainly arose from Manager Gene Mauch's\\r\\n: ineptitude in managin...   \n",
       "16360  OK... quick scenario... you're at home, not bothering anybody... next thing you\\r\\nknow, somebod...   \n",
       "\n",
       "                                                                                             Clean Article  \\\n",
       "4105   little nitpicking not government require standard railway gauge not improve thing please not mis...   \n",
       "12650  mean eff public stance complicate issue irrelevant encryption issue per se may well people care ...   \n",
       "7039   flash light chap front not pass next major highway lane direction keep extreme right block folk ...   \n",
       "3310   think problem mainly arise manager gene mauchs ineptitude manage pitching staff stretch abuse ji...   \n",
       "16360  ok quick scenario home not bother anybody next thing know somebody come crash upstairs window he...   \n",
       "\n",
       "       Target Label         Target Name      Predicted Name  \\\n",
       "4105             11           sci.crypt           sci.crypt   \n",
       "12650            11           sci.crypt           sci.crypt   \n",
       "7039              7           rec.autos     rec.motorcycles   \n",
       "3310              9  rec.sport.baseball  rec.sport.baseball   \n",
       "16360            16  talk.politics.guns  talk.politics.guns   \n",
       "\n",
       "       Predicted Confidence  \n",
       "4105               0.975658  \n",
       "12650              0.988600  \n",
       "7039               0.729504  \n",
       "3310               0.999942  \n",
       "16360              0.998837  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_probas = gs_mnb.predict_proba(test_corpus).max(axis=1)\n",
    "test_df = data_df.iloc[test_idx]\n",
    "test_df['Predicted Name'] = mnb_predictions\n",
    "test_df['Predicted Confidence'] = predict_probas\n",
    "test_df.head()\n",
    "# Adding additional metadata to our test dataset with model\n",
    "# predictions and confidence scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Clean Article</th>\n",
       "      <th>Target Label</th>\n",
       "      <th>Target Name</th>\n",
       "      <th>Predicted Name</th>\n",
       "      <th>Predicted Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8968</th>\n",
       "      <td>\\r\\nZoroaster is far older than Daniel. If anything, one could claim that,\\r\\nin a sense, Daniel is a descendant of Zoroaster; as Daniel, though being\\r\\nHebrew, has assimilated into Zoroastrianis...</td>\n",
       "      <td>zoroaster far old daniel anything one could claim sense daniel descendant zoroaster daniel though hebrew assimilate zoroastrianism successfully introduce religion tanakh judaism however majority b...</td>\n",
       "      <td>19</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "      <td>0.999557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3299</th>\n",
       "      <td>There were some recent developments in the dispute about Masonry among\\r\\nSouthern Baptists.  I posted a summary over in bit.listserv.christia, and\\r\\nI suppose that it might be useful here.  Note...</td>\n",
       "      <td>recent development dispute masonry among southern baptists post summary bit listserv christia suppose may useful note not necessarily agree disagree follow present information short summary southe...</td>\n",
       "      <td>19</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "      <td>0.999384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4367</th>\n",
       "      <td>:\\r\\n (lots of stuff about the Nicene Creed deleted which can be read in the\\r\\n  original basenote.  I will also leave it up to other LDS netters to\\r\\n  take Mr. Weiss to task on using Mormon Do...</td>\n",
       "      <td>lot stuff nicene creed delete read original basenote also leave lds netter take mr weiss task use mormon doctrine declare difinitive word lds church teach doctrine hopefully lds netter amiable exp...</td>\n",
       "      <td>19</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "      <td>0.999254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12608</th>\n",
       "      <td>: &gt;: &gt;&gt; Gilligan = Sloth\\r\\n: &gt;: &gt;&gt; Skipper = Anger\\r\\n: &gt;: &gt;&gt; Thurston Howell III = Greed\\r\\n: &gt;: &gt;&gt; Lovey Howell = Gluttony\\r\\n: &gt;: &gt;&gt; Ginger = Lust\\r\\n: &gt;: &gt;&gt; Professor = Pride\\r\\n: &gt;: &gt;&gt; Mary ...</td>\n",
       "      <td>gilligan sloth skipper anger thurston howell iii greed lovey howell gluttony ginger lust professor pride mary ann envy assorted monkeys secular humanism assorted headhunters godless heathen savage...</td>\n",
       "      <td>19</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "      <td>0.998755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16758</th>\n",
       "      <td>\\r\\n\\r\\nThere were many injustices in the middle ages.  And this is truely sad.\\r\\nI would hate to see a day when churches put people to death or torchured\\r\\nthem for practicing homosexuality, or...</td>\n",
       "      <td>many injustice middle age truely sad would hate see day church put people death torchur practice homosexuality crime church not call take government world may homosexual treat cruelly today not me...</td>\n",
       "      <td>19</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "      <td>0.998243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                       Article  \\\n",
       "8968   \\r\\nZoroaster is far older than Daniel. If anything, one could claim that,\\r\\nin a sense, Daniel is a descendant of Zoroaster; as Daniel, though being\\r\\nHebrew, has assimilated into Zoroastrianis...   \n",
       "3299   There were some recent developments in the dispute about Masonry among\\r\\nSouthern Baptists.  I posted a summary over in bit.listserv.christia, and\\r\\nI suppose that it might be useful here.  Note...   \n",
       "4367   :\\r\\n (lots of stuff about the Nicene Creed deleted which can be read in the\\r\\n  original basenote.  I will also leave it up to other LDS netters to\\r\\n  take Mr. Weiss to task on using Mormon Do...   \n",
       "12608  : >: >> Gilligan = Sloth\\r\\n: >: >> Skipper = Anger\\r\\n: >: >> Thurston Howell III = Greed\\r\\n: >: >> Lovey Howell = Gluttony\\r\\n: >: >> Ginger = Lust\\r\\n: >: >> Professor = Pride\\r\\n: >: >> Mary ...   \n",
       "16758  \\r\\n\\r\\nThere were many injustices in the middle ages.  And this is truely sad.\\r\\nI would hate to see a day when churches put people to death or torchured\\r\\nthem for practicing homosexuality, or...   \n",
       "\n",
       "                                                                                                                                                                                                 Clean Article  \\\n",
       "8968   zoroaster far old daniel anything one could claim sense daniel descendant zoroaster daniel though hebrew assimilate zoroastrianism successfully introduce religion tanakh judaism however majority b...   \n",
       "3299   recent development dispute masonry among southern baptists post summary bit listserv christia suppose may useful note not necessarily agree disagree follow present information short summary southe...   \n",
       "4367   lot stuff nicene creed delete read original basenote also leave lds netter take mr weiss task use mormon doctrine declare difinitive word lds church teach doctrine hopefully lds netter amiable exp...   \n",
       "12608  gilligan sloth skipper anger thurston howell iii greed lovey howell gluttony ginger lust professor pride mary ann envy assorted monkeys secular humanism assorted headhunters godless heathen savage...   \n",
       "16758  many injustice middle age truely sad would hate see day church put people death torchur practice homosexuality crime church not call take government world may homosexual treat cruelly today not me...   \n",
       "\n",
       "       Target Label         Target Name          Predicted Name  \\\n",
       "8968             19  talk.religion.misc  soc.religion.christian   \n",
       "3299             19  talk.religion.misc  soc.religion.christian   \n",
       "4367             19  talk.religion.misc  soc.religion.christian   \n",
       "12608            19  talk.religion.misc  soc.religion.christian   \n",
       "16758            19  talk.religion.misc  soc.religion.christian   \n",
       "\n",
       "       Predicted Confidence  \n",
       "8968               0.999557  \n",
       "3299               0.999384  \n",
       "4367               0.999254  \n",
       "12608              0.998755  \n",
       "16758              0.998243  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 200)\n",
    "res_df = (test_df[(test_df['Target Name'] == 'talk.religion.misc') & (test_df['Predicted Name'] == 'soc.religion.christian')]\n",
    "       .sort_values(by=['Predicted Confidence'], ascending=False).head(5))\n",
    "res_df\n",
    "# Looking at mode misclassification instances for religion.misc and\n",
    "# religion.christian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Clean Article</th>\n",
       "      <th>Target Label</th>\n",
       "      <th>Target Name</th>\n",
       "      <th>Predicted Name</th>\n",
       "      <th>Predicted Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>\\r\\n\\r\\nAtoms are not objective.  They aren't even real.  What scientists call\\r\\nan atom is nothing more than a mathematical model that describes \\r\\ncertain physical, observable properties of ou...</td>\n",
       "      <td>atom not objective not even real scientist call atom nothing mathematical model describe certain physical observable property surrounding subjective objective though approach scientist take discus...</td>\n",
       "      <td>19</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>0.996075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2334</th>\n",
       "      <td>In &lt;1ren9a$94q@morrow.stanford.edu&gt; salem@pangea.Stanford.EDU (Bruce Salem) \\r\\n\\r\\n\\r\\n\\r\\nThis brings up another something I have never understood.  I asked this once\\r\\nbefore and got a few int...</td>\n",
       "      <td>renaqmorrow stanford edu salempangea stanford edu bruce salem bring another something never understand ask get interesting response somehow not seem satisfied would nt not consider good source may...</td>\n",
       "      <td>19</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>0.996051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11117</th>\n",
       "      <td>\\r\\n\\r\\n\\tUnless God admits that he didn't do it....\\r\\n\\r\\n\\t=)\\r\\n\\r\\n\\r\\n---  \\r\\n\\r\\n  \" I'd Cheat on Hillary Too.\"</td>\n",
       "      <td>unless god admit not would cheat hillary</td>\n",
       "      <td>19</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>0.965725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12386</th>\n",
       "      <td>\\r\\nAh, you taking everything as literal quotation.  No wonder you're confused.\\r\\n\\r\\nFirst, can I ask that we decide on a definition of \"objective\"?\\r\\n\\r\\n\\r\\nAnd?\\r\\n\\r\\n\\r\\nI'd guess that it ...</td>\n",
       "      <td>ah take everything literal quotation no wonder confused first ask decide definition objective would guess may may case people unable evaluate complex moral issue rather leave behave immorally may ...</td>\n",
       "      <td>19</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>0.772658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9360</th>\n",
       "      <td>\\r\\nYes, as a philosophy weak atheism is worthless.  This is true in\\r\\nexactly the same sense that as a philosophy Christians' disbelief in\\r\\nZeus is worthless.  Atheists construct their persona...</td>\n",
       "      <td>yes philosophy weak atheism worthless true exactly sense philosophy christian disbelief zeus worthless atheists construct personal philosophy many different source build non god base idea way chri...</td>\n",
       "      <td>19</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>0.757788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                       Article  \\\n",
       "914    \\r\\n\\r\\nAtoms are not objective.  They aren't even real.  What scientists call\\r\\nan atom is nothing more than a mathematical model that describes \\r\\ncertain physical, observable properties of ou...   \n",
       "2334   In <1ren9a$94q@morrow.stanford.edu> salem@pangea.Stanford.EDU (Bruce Salem) \\r\\n\\r\\n\\r\\n\\r\\nThis brings up another something I have never understood.  I asked this once\\r\\nbefore and got a few int...   \n",
       "11117                                                                                  \\r\\n\\r\\n\\tUnless God admits that he didn't do it....\\r\\n\\r\\n\\t=)\\r\\n\\r\\n\\r\\n---  \\r\\n\\r\\n  \" I'd Cheat on Hillary Too.\"   \n",
       "12386  \\r\\nAh, you taking everything as literal quotation.  No wonder you're confused.\\r\\n\\r\\nFirst, can I ask that we decide on a definition of \"objective\"?\\r\\n\\r\\n\\r\\nAnd?\\r\\n\\r\\n\\r\\nI'd guess that it ...   \n",
       "9360   \\r\\nYes, as a philosophy weak atheism is worthless.  This is true in\\r\\nexactly the same sense that as a philosophy Christians' disbelief in\\r\\nZeus is worthless.  Atheists construct their persona...   \n",
       "\n",
       "                                                                                                                                                                                                 Clean Article  \\\n",
       "914    atom not objective not even real scientist call atom nothing mathematical model describe certain physical observable property surrounding subjective objective though approach scientist take discus...   \n",
       "2334   renaqmorrow stanford edu salempangea stanford edu bruce salem bring another something never understand ask get interesting response somehow not seem satisfied would nt not consider good source may...   \n",
       "11117                                                                                                                                                                 unless god admit not would cheat hillary   \n",
       "12386  ah take everything literal quotation no wonder confused first ask decide definition objective would guess may may case people unable evaluate complex moral issue rather leave behave immorally may ...   \n",
       "9360   yes philosophy weak atheism worthless true exactly sense philosophy christian disbelief zeus worthless atheists construct personal philosophy many different source build non god base idea way chri...   \n",
       "\n",
       "       Target Label         Target Name Predicted Name  Predicted Confidence  \n",
       "914              19  talk.religion.misc    alt.atheism              0.996075  \n",
       "2334             19  talk.religion.misc    alt.atheism              0.996051  \n",
       "11117            19  talk.religion.misc    alt.atheism              0.965725  \n",
       "12386            19  talk.religion.misc    alt.atheism              0.772658  \n",
       "9360             19  talk.religion.misc    alt.atheism              0.757788  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 200)\n",
    "res_df = (test_df[(test_df['Target Name'] == 'talk.religion.misc') & (test_df['Predicted Name'] == 'alt.atheism')]\n",
    "       .sort_values(by=['Predicted Confidence'], ascending=False).head(5))\n",
    "res_df"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
